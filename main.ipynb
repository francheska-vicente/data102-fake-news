{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3058ede7",
   "metadata": {},
   "source": [
    "# Insert Title Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb937d43",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08df81d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams\n",
    "\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd21c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f518d",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c898287c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading fake news datasets and storing into DataFrames\n",
    "df_fakenews1 = pd.read_csv('https://raw.githubusercontent.com/francheska-vicente/data102-fake-news/main/data/fake%20news%20dataset.csv?token=GHSAT0AAAAAACFFAWG2WCYBUFOWTXDHEOMCZF2KFKQ')\n",
    "df_fakenews1.rename(columns={'article': 'Content'}, inplace=True) #renamed column\n",
    "\n",
    "df_fakenews2 = pd.read_csv('https://raw.githubusercontent.com/francheska-vicente/data102-fake-news/main/data/fake_or_real_news.csv?token=GHSAT0AAAAAACFFAWG2H62FDYK4S7SVJTSQZF2KFUQ')\n",
    "df_fakenews2.rename(columns={'text': 'Content'}, inplace=True) #renamed column\n",
    "\n",
    "#combining two dataset into a single DataFrame\n",
    "df_FakeNews = pd.concat([df_fakenews1, df_fakenews2], ignore_index=True)\n",
    "\n",
    "# Drop irrelevant columns\n",
    "df_FakeNews = df_FakeNews.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "#assigning new values (raplacing the existing values 'REAL' and 'FAKE' with 0 and 1, respectively in the 'label' column)\n",
    "df_FakeNews.loc[:, 'label'] = df_FakeNews['label'].replace({'REAL': 0, 'FAKE': 1})\n",
    "df_FakeNews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a2c9a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39585e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading news sites datasets and storing into DataFrames\n",
    "df_rapplerlinks = pd.read_csv('https://raw.githubusercontent.com/francheska-vicente/data102-fake-news/main/rappfinlink.csv?token=GHSAT0AAAAAACFFAWG2UN7DVEMCNZOLNPOIZF2LIAQ')\n",
    "df_rapplerlinks.rename(columns={'https://www.rappler.com/world/asia-pacific/thailand-opposition-crushes-military-parties-election-2023/': 'Link'}, inplace=True) #renamed column\n",
    "\n",
    "df_rappler1 = pd.read_csv('https://raw.githubusercontent.com/francheska-vicente/data102-fake-news/main/rap_dataframe.csv?token=GHSAT0AAAAAACFFAWG3EYG2PHJS5PG7QJIEZF2LHJA')\n",
    "\n",
    "df_Rappler = pd.concat([df_rappler1,df_rapplerlinks], ignore_index=True)\n",
    "df_Rappler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gma1 = pd.read_csv('https://raw.githubusercontent.com/francheska-vicente/data102-fake-news/main/data/gma-10000.csv?token=GHSAT0AAAAAACFFAWG3C6UINZTQ474HBPHEZF2LFPA')\n",
    "\n",
    "df_gma2 = pd.read_csv('https://raw.githubusercontent.com/francheska-vicente/data102-fake-news/main/data/gma_dataframe.csv?token=GHSAT0AAAAAACFFAWG3KBL5EAXUXXKUOV4UZF2KE5A')\n",
    "\n",
    "df_GMA = pd.concat([df_gma1,df_gma2], ignore_index=True)\n",
    "\n",
    "df_GMA = df_GMA.drop('Unnamed: 0', axis=1)\n",
    "df_GMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217cf0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df_FakeNews = df_FakeNews.drop_duplicates()\n",
    "df_Rappler = df_Rappler.drop_duplicates()\n",
    "df_GMA = df_GMA.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f3bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "display(\"df_FakeNews\",df_FakeNews.head(),\n",
    "        \"df_Rappler\", df_Rappler.head(), \n",
    "        \"df_GMA\", df_GMA.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cd761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_News = pd.concat([df_FakeNews,df_Rappler, df_GMA], ignore_index=True)\n",
    "\n",
    "# Drop duplicates\n",
    "df_News = df_News.drop_duplicates()\n",
    "df_News\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabba766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to remove '\\n' and '\\t'\n",
    "def remove_newline_tab(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.replace(r'\\n', ' ').replace(r'\\t', ' ')\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Apply preprocessing to 'Content' column in df_News\n",
    "df_News['Content'] = df_News['Content'].apply(remove_newline_tab)\n",
    "df_News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function to remove links from text\n",
    "def remove_links(text):\n",
    "    # Regular expression pattern to match URLs\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    \n",
    "    # Replace URLs with an empty string\n",
    "    return re.sub(url_pattern, '', text)\n",
    "\n",
    "    # Apply preprocessing to 'Content' column in df_News\n",
    "df_News['Content'] = df_News['Content'].astype(str).apply(remove_links)\n",
    "df_News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d5419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_images(text):\n",
    "    # Define a regular expression pattern to match base64-encoded strings (images)\n",
    "    base64_pattern = r\"data:image\\/(png|jpg|jpeg|gif|bmp);base64,[A-Za-z0-9+/=]+\"\n",
    "\n",
    "    # Use the re.sub() function to replace the base64-encoded strings with an empty string\n",
    "    cleaned_text = re.sub(base64_pattern, '', text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "df_News['Content'] = df_News['Content'].astype(str).apply(remove_images)\n",
    "df_News\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79850218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving of Cleaned Data to CSV file\n",
    "df_News.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d96ee8",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fb8211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "971ee42c",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b69615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec63bc36",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26c4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "028fab13",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b57fa",
   "metadata": {},
   "source": [
    "## References"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
