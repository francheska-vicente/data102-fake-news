{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbabd52",
   "metadata": {},
   "source": [
    "# Insert Title Here\n",
    "**DATA102 S11 Group 3*\n",
    "- Banzon, Beatrice Elaine B.\n",
    "- Buitre, Cameron\n",
    "- Marcelo, Andrea Jean C.\n",
    "- Navarro, Alyssa Riantha R.\n",
    "- Vicente, Francheska Josefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e7d6c5",
   "metadata": {},
   "source": [
    "# **Requirements and Imports**\n",
    "Before starting, the relevant libraries and files in building and training the model should be loaded into the notebook first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa764da",
   "metadata": {},
   "source": [
    "## **Basic** Libraries\n",
    "* `numpy` contains a large collection of mathematical functions\n",
    "* `pandas` contains functions that are designed for data manipulation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ef3c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32a8aa",
   "metadata": {},
   "source": [
    "## **`Natural Language Processing`** Libraries\n",
    "* `train_test_split` is a function that allows the dataset to be split into two randomly.\n",
    "* `TFidfVectorizer` converts the given text documents into a matrix, which has TF-IDF features\n",
    "* `CountVectorizer` converts the given text documents into a matrix, which has the counts of the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa85e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45175c",
   "metadata": {},
   "source": [
    "## **`Machine Learning`** Libraries\n",
    "The following classes are models that implement different methods of clustering or classification.\n",
    "- `KMeans` is a class under the cluster models module that implements k-means clustering.\n",
    "- `LogisticRegression` is a class under the linear models module that implements regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06bacb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06feb8f",
   "metadata": {},
   "source": [
    "Next is the `shuffle` function which shuffles matrices and arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9700e313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610a920a",
   "metadata": {},
   "source": [
    "On the other hand, these classes computes and visualizes the different scores about how well a model works.\n",
    "* `f1_score` computes the balanced F-score by comparing the actual classes and the predicted classes\n",
    "* `hamming_loss` computes the fraction of labels that were incorrectly labeled by the model\n",
    "* `accuracy_score` computes the accuracy by determining how many classes were correctly predicted\n",
    "* `precision_recall_fscore_support`computes the precision, recall, F-measure and support per class\n",
    "* `ConfusionMatrixDisplay` allows the visualization of the computed confusion matrix\n",
    "* `confusion_matrix`  is a function that displays the number of samples that are correctly and incorrectly labeled by the model, by grouping them into four groups (i.e., True Positives, False Positives, True Negatives, False Negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3070658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, hamming_loss, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6af1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdbc3aa",
   "metadata": {},
   "source": [
    "Meanwhile, `GridSearchCV` is a cross-validation class that allows the exhaustive search over all possible combinations of hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0742d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ccd45a",
   "metadata": {},
   "source": [
    "Last, `pickle` is a module that can serialize and deserialize objects. In this notebook, it is used to save and load models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e3d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e262f2",
   "metadata": {},
   "source": [
    "### Datasets and Files\n",
    "To train the models that utilizes the traditional machine learning algorithms, the dataset that was cleaned will be loaded using the [`read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293001b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv ('cleaned_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26429e9a",
   "metadata": {},
   "source": [
    "# **Feature Engineering**\n",
    "\n",
    "As we cannot directly feed the text data as input to the machine learning models, we have to convert it into the format that they can understandâ€”numbers. Before doing that, since we want to save the models and vectorizers that we will be using, we will first need to define the values and functions to do so, starting with the folder where we will be saving it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985808d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_directory = './saved_models/Clustering/vectorizers/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eaaa0c",
   "metadata": {},
   "source": [
    "Next, we will be creating a function that will be saving the vectorizer to the specified path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8901698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vectorizers (vectorizer, vectorizer_name):\n",
    "    vectorizer_filename = main_directory + vectorizer_name + '.pkl'\n",
    "    \n",
    "    with open(vectorizer_filename, 'wb') as file:\n",
    "        pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08e652",
   "metadata": {},
   "source": [
    "## Splitting the Dataset into **`Train`**, **`Validation`**, and **`Test`** Split\n",
    "Let us first define the **X** (input) and **y** (target/output) of our model. This is done to allow the stratifying of the data when it is split into the train, val and test.\n",
    "\n",
    "The **X** (input) can be retrieved by getting the `text` column in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f67c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df ['text']\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf9563",
   "metadata": {},
   "source": [
    "Meanwhile, the **y** value (i.e., the value that we would be \"feeding\" our models) is the `label` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c61b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df ['label']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228fd64c",
   "metadata": {},
   "source": [
    "Now that we have declared the input and the target output of our models, we can use the [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function to divide the dataset into two splits. Some things to note are: (1) the split is stratified based on the **y values**, (2) the value of the random state was set to 42 for reproducibility, and (3) the dataset is shuffled.\n",
    "\n",
    "First, let us create the train and test set. The test set is made up of 20% of the original dataset, which infers that the second split is 80% of the original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6e8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 42, \n",
    "                                                    shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b56c1",
   "metadata": {},
   "source": [
    "Second, we will be splitting the remaining 80% of the original dataset into two: the train and val sets. The train set will be 90% of the second split, while the val set will be 10% of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5b204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                  y_train, \n",
    "                                                  test_size = 0.1,\n",
    "                                                  stratify = y_train,\n",
    "                                                  random_state = 42, \n",
    "                                                  shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d4021",
   "metadata": {},
   "source": [
    "However, since we want to test if deciding the `class` of the prediction based on the dominant class of the points in a cluster is enough, we want to make sure that the train dataset has equal number of instances for each of the class.  To do this, we created a function that would ensure that the number of positive and negative instances are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a287de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe (df):\n",
    "    true_df = df [df ['label'] == 1][['text', 'label']]\n",
    "    false_df = df [df ['label'] == 0][['text', 'label']]\n",
    "    \n",
    "    num_of_true = len(true_df)\n",
    "    \n",
    "    false_df = false_df.sample(n = num_of_true)\n",
    "    false_df = false_df.reset_index(drop=True)\n",
    "    \n",
    "    df = false_df.append(true_df, ignore_index = True)\n",
    "    df = shuffle(df.reset_index(drop=True)).reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac06be6",
   "metadata": {},
   "source": [
    "To easily divide the train set, let us first [`concat`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)enate the X_train and y_train into one DataFrame. In addition to this, to ensure that the index of the DataFrame is sequential, we would be using the [`reset_index`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac934b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train], axis = 1).reset_index(drop = True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375013ec",
   "metadata": {},
   "source": [
    "Using the combined DataFrame, we would be creating a DataFrame that has equal number of positive and negative instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cbf4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = make_dataframe (train_df)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91c8ac",
   "metadata": {},
   "source": [
    "As we have changed the train dataset, we would be re-declaring the values for the X and y of the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed811fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df ['text']\n",
    "y_train = train_df ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bdfa40",
   "metadata": {},
   "source": [
    "For consistency, we would also be [`concat`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)enating the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d221b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.concat([X_val, y_val], axis = 1).reset_index(drop = True)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c10cb",
   "metadata": {},
   "source": [
    "And lastly, the test set would also be [`concat`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)enated into one DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511932da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([X_test, y_test], axis = 1).reset_index(drop = True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca092ffd",
   "metadata": {},
   "source": [
    "To check if the shapes of the input and output are the same, we will be looking at the shapes of the resulting DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b63dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train')\n",
    "print('Input  shape: ', X_train.shape)\n",
    "print('Output shape: ', y_train.shape, '\\n')\n",
    "\n",
    "print('Val')\n",
    "print('Input  shape: ', X_val.shape)\n",
    "print('Output shape: ', y_val.shape, '\\n')\n",
    "\n",
    "print('Test')\n",
    "print('Input  shape: ', X_test.shape)\n",
    "print('Output shape: ', y_test.shape, '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e0ac26",
   "metadata": {},
   "source": [
    "## Tokenizing with **`TF-IDF` Vectorizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1138e34c",
   "metadata": {},
   "source": [
    "Now, we can proceed with tokenizing our input. To do this, we first create an instance of a [`TF-IDF Vectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) with english stopwords as its list of stopwords and a maximum feature of 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29106a1",
   "metadata": {},
   "source": [
    "### **`Train`** Data\n",
    "With the created vectorizer, we can now use the [`fit_transform`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer.fit_transform) function, which will learn the vocabulary and the inverse document frequency from the data provided, and then create a document-term matrix using the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a91dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train.values.astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040e8a4",
   "metadata": {},
   "source": [
    "To use this vectorizer that has learned from the vocabulary, let us save it using the function we previously defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048397df",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_vectorizers(tfidf_vectorizer, 'tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2749177",
   "metadata": {},
   "source": [
    "### **`Validation`** Data\n",
    "Using the [`transform`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer.transform) function, we will be creating a document-term matrix for the validation set. For this, it is important to convert the datatype of the values in the validation set into **Unicode**, as this is the type accepted by the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_val = tfidf_vectorizer.transform(X_val.values.astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d4448",
   "metadata": {},
   "source": [
    "### **`Test`** Data\n",
    "Next, we will also [`transform`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer.transform) our test data into a document-term matrix, and to do this, we also have to convert it into the **Unicode** datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bae28b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = tfidf_vectorizer.transform(X_test.values.astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f737feeb",
   "metadata": {},
   "source": [
    "## Tokenizing with **`Count` Vectorizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd5bc6c",
   "metadata": {},
   "source": [
    "We create a [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) object, with the same parameter values as the [`TF-IDF Vectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61cdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = 'english', max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b03d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train.values.astype('U'))\n",
    "save_vectorizers(count_vectorizer, 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e5806",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_val = count_vectorizer.transform(X_val.values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab4233",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test.values.astype('U'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75bb115",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation\n",
    "Now that we have transformed our data into the format that our algorithms can understand, we can move on to the modeling proper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e5273",
   "metadata": {},
   "source": [
    "## Defining the **Functions**\n",
    "To start with, let us first define the functions and the values needed to easily train the model. First, we would be creating a function that would convert the cluster number of the points into a prediction of 0 or 1 (i.e,. news or fake news). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e984b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_label (prediction, labels_per_cluster):\n",
    "    return labels_per_cluster [prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f6425d",
   "metadata": {},
   "source": [
    "Next, we will be creating a function that will call the functions for the metrics (i.e., [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), [`f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html), [`hamming_loss`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html), and [`precision_recall_fscore_support`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)) that are used for the scoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafaf361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores (y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true = y_true, y_pred = y_pred)   \n",
    "    f1_micro_average = f1_score(y_true = y_true, y_pred = y_pred, average = 'micro')\n",
    "    f1_macro_average = f1_score(y_true = y_true, y_pred = y_pred, average = 'macro')\n",
    "    hamming_loss_score = hamming_loss(y_true = y_true, y_pred = y_pred)\n",
    "    precision, recall, _, _ = precision_recall_fscore_support(y_true, y_pred, average = 'weighted')\n",
    "    \n",
    "    return accuracy, f1_micro_average, f1_macro_average, hamming_loss_score, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2480ce28",
   "metadata": {},
   "source": [
    "To be able to view the scores in a readable format, we also created a function that would create a dictionary out of the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_scores (k, y_true, y_pred):\n",
    "    accuracy, f1_micro_average, f1_macro_average, hamming_loss_score, precision, recall = scores (y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'K' : k,\n",
    "        'Accuracy' : accuracy,\n",
    "        'F1 Micro Average' : f1_micro_average,\n",
    "        'F1 Macro Average' : f1_macro_average,\n",
    "        'Hamming Loss' : hamming_loss_score,\n",
    "        'Precision' : precision,\n",
    "        'Recall' : recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eade14e",
   "metadata": {},
   "source": [
    "Next, since we would be experimenting on two ways to predict using clusters (i.e., predicting by looking at the dominant class per cluster, and using the cluster number as additional information in a Logistic Regresion model), we would be defining functions that could do the clustering and prediction in these two ways.\n",
    "\n",
    "The `cluster_categorize_predict` is the function that would be used for the latter process. In this function, there are four major steps: (1) the points are clustered by the trained K-means clustering model, (2) the predictions are appended to the dataset, (3) the Logistic Regression model was used to predict the resulting DataFrame (i.e., the one where the clusters were appended into), and (4) the score of the model was computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669e7f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_categorize_predict (k, orig_df, df_set, km, model, vectorizer):\n",
    "    predictions = km.predict (df_set)\n",
    "    converted_df = pd.DataFrame(df_set.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "    \n",
    "    labeled_df = orig_df.copy() \n",
    "    labeled_df ['predictions'] = predictions \n",
    "    \n",
    "    temp_x = pd.concat ([converted_df, labeled_df ['predictions']], axis = 1)\n",
    "    \n",
    "    predictions = model.predict (temp_x.values)\n",
    "    \n",
    "    dict_scores = format_scores (k, labeled_df ['label'], val_predictions)\n",
    "    \n",
    "    return dict_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe75a278",
   "metadata": {},
   "source": [
    "Then, the `cluster_then_categorize_news` function is used to: (1) train the model that is used for k-means clustering, (2) predict on the train data using the k-means, (3) concatenate the cluster result of the k-means model to the vectorized matrix, (4) train the Logistic Regression model using the resulting matrix, and (5) predict on the test set by calling `cluster_categorize_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536736d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_then_categorize_news (k, train_set, val_set, model, vectorizer):\n",
    "    label_per_cluster = {}\n",
    "    \n",
    "    km = KMeans (n_clusters = k, random_state = 42)\n",
    "    km.fit (train_set)\n",
    "    train_predictions = km.predict (train_set)\n",
    "    converted_train = pd.DataFrame(train_set.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "    \n",
    "    train_labeled_df = train_df.copy() \n",
    "    train_labeled_df ['predictions'] = train_predictions\n",
    "    \n",
    "    temp_x_train = pd.concat ([converted_train, train_labeled_df ['predictions']], axis = 1)\n",
    "\n",
    "    model.fit (temp_x_train.values, y_train)\n",
    "\n",
    "    dict_scores = cluster_categorize_predict (k, val_df, val_set, km, model, vectorizer)\n",
    "        \n",
    "    return dict_scores, km, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547e91b2",
   "metadata": {},
   "source": [
    "Last, the `cluster_news` function is used for the former process of predicting using the cluster. In this, instead of using the cluster number as an additional feature for the Logistic Regression model, it just converts the cluster number to the dominant class per cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a178d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_news (k, train_set, val_set):\n",
    "    label_per_cluster = {}\n",
    "    \n",
    "    km = KMeans (n_clusters = k, random_state = 42)\n",
    "    km.fit (train_set)\n",
    "    train_predictions = km.predict (train_set)\n",
    "    train_labeled_df = train_df.copy() \n",
    "    train_labeled_df ['predictions'] = train_predictions\n",
    "\n",
    "    for i in range (k + 1):\n",
    "        dominant_label = train_labeled_df.groupby ('predictions')[['label']].value_counts().index [i][1]\n",
    "        label_per_cluster [i] = dominant_label\n",
    "    \n",
    "    train_labeled_df ['predictions'] = train_labeled_df ['predictions'].replace(labels_per_cluster)\n",
    "\n",
    "    dict_scores = format_scores (k, train_labeled_df ['label'], train_labeled_df ['predictions'])\n",
    "\n",
    "    val_predictions = km.predict (val_set)\n",
    "    val_labeled_df = val_df.copy() \n",
    "    val_labeled_df ['predictions'] = val_predictions \n",
    "    val_labeled_df ['predictions'] = val_labeled_df ['predictions'].replace(labels_per_cluster)\n",
    "\n",
    "    dict_scores = format_scores (k, val_labeled_df ['label'], val_labeled_df ['predictions'])\n",
    "        \n",
    "    return dict_scores, km, label_per_cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425276b",
   "metadata": {},
   "source": [
    "## K-means (TF-IDF Vectorizer)\n",
    "With all of the relevant functions declared, we can now proceed with the actual training proper.\n",
    "\n",
    "For the first model, we would be using the resulting matrix from the [`TF-IDF Vectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to train the k-means model. The resulting clusters would determine the class of the text by getting the dominant class in a cluster.\n",
    "\n",
    "To do this, we will first declare a dictionary that would hold the dominant class per cluster number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71931042",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_per_cluster = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abf9b53",
   "metadata": {},
   "source": [
    "To be able to find the best k-value for the model, we would be creating a list that would hold the scores of the each of the value of the k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9926ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_val_scores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49827308",
   "metadata": {},
   "source": [
    "In addition to the scores, we would have to create a list of k-means model and the list of dictionaries that would allow us to use the best model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a41ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_models = []\n",
    "tfidf_labels_per_cluster = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594f9051",
   "metadata": {},
   "source": [
    "With these, we can start training k-means clustering models with different k valuesusing the `cluster_news` function. This would allow us to determine which k-value would result in the highest validation score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f150b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in range (1, 60):\n",
    "    val_score, model, label = cluster_news (k, tfidf_train, tfidf_val)\n",
    "    tfidf_val_scores.append (val_score)\n",
    "    tfidf_models.append (model)\n",
    "    tfidf_labels_per_cluster.append (label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9a49e",
   "metadata": {},
   "source": [
    "With the training of the models finished, we can now look at the DataFrame of their validation scores. Using the [`sort_values`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html) function, we would be sorting the scores of the model by the **Recall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd92cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame (tfidf_val_scores)\n",
    "scores_df = scores_df.sort_values ('F1 Macro Average', ascending = False)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db06c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_index = int (scores_df.loc [0]['K']) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = tfidf_models [best_model_index].predict (tfidf_val)\n",
    "val_labeled_df = val_df.copy() \n",
    "val_labeled_df ['predictions'] = val_predictions \n",
    "val_labeled_df ['predictions'] = val_labeled_df ['predictions'].replace(tfidf_labels_per_cluster [best_model_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38adec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = format_scores (best_model_index + 1, val_labeled_df ['label'], val_labeled_df ['predictions'])\n",
    "dict_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c30a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = tfidf_models [best_model_index].predict (tfidf_test)\n",
    "test_labeled_df = test_df.copy() \n",
    "test_labeled_df ['predictions'] = test_predictions \n",
    "test_labeled_df ['predictions'] = test_labeled_df ['predictions'].replace(tfidf_labels_per_cluster [best_model_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e985b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = format_scores (best_model_index - 1, test_labeled_df ['label'], test_labeled_df ['predictions'])\n",
    "dict_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fde69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(test_labeled_df ['label'], test_labeled_df ['predictions'])).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df605afb",
   "metadata": {},
   "source": [
    "## K-means (Count Vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31a223b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_val_scores = []\n",
    "count_models = []\n",
    "count_labels_per_cluster = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2470b751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for k in range (1, 60):\n",
    "    val_score, model, label = cluster_news (k, count_train, count_val)\n",
    "    count_val_scores.append (val_score)\n",
    "    count_models.append (model)\n",
    "    count_labels_per_cluster.append (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5adfafc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Micro Average</th>\n",
       "      <th>F1 Macro Average</th>\n",
       "      <th>Hamming Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.802269</td>\n",
       "      <td>0.802269</td>\n",
       "      <td>0.445144</td>\n",
       "      <td>0.197731</td>\n",
       "      <td>0.643636</td>\n",
       "      <td>0.802269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.562240</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.678012</td>\n",
       "      <td>0.678012</td>\n",
       "      <td>0.367040</td>\n",
       "      <td>0.321988</td>\n",
       "      <td>0.728120</td>\n",
       "      <td>0.678012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.588871</td>\n",
       "      <td>0.588871</td>\n",
       "      <td>0.151680</td>\n",
       "      <td>0.411129</td>\n",
       "      <td>0.726549</td>\n",
       "      <td>0.588871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.573204</td>\n",
       "      <td>0.573204</td>\n",
       "      <td>0.136907</td>\n",
       "      <td>0.426796</td>\n",
       "      <td>0.717389</td>\n",
       "      <td>0.573204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>0.320367</td>\n",
       "      <td>0.320367</td>\n",
       "      <td>0.038904</td>\n",
       "      <td>0.679633</td>\n",
       "      <td>0.700796</td>\n",
       "      <td>0.320367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.243112</td>\n",
       "      <td>0.243112</td>\n",
       "      <td>0.061993</td>\n",
       "      <td>0.756888</td>\n",
       "      <td>0.842545</td>\n",
       "      <td>0.243112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.172880</td>\n",
       "      <td>0.172880</td>\n",
       "      <td>0.079071</td>\n",
       "      <td>0.827120</td>\n",
       "      <td>0.606959</td>\n",
       "      <td>0.172880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.139384</td>\n",
       "      <td>0.139384</td>\n",
       "      <td>0.024917</td>\n",
       "      <td>0.860616</td>\n",
       "      <td>0.794527</td>\n",
       "      <td>0.139384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.121556</td>\n",
       "      <td>0.121556</td>\n",
       "      <td>0.039764</td>\n",
       "      <td>0.878444</td>\n",
       "      <td>0.653498</td>\n",
       "      <td>0.121556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.119395</td>\n",
       "      <td>0.119395</td>\n",
       "      <td>0.052494</td>\n",
       "      <td>0.880605</td>\n",
       "      <td>0.033155</td>\n",
       "      <td>0.119395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.109130</td>\n",
       "      <td>0.109130</td>\n",
       "      <td>0.079938</td>\n",
       "      <td>0.890870</td>\n",
       "      <td>0.638256</td>\n",
       "      <td>0.109130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>0.097785</td>\n",
       "      <td>0.097785</td>\n",
       "      <td>0.018511</td>\n",
       "      <td>0.902215</td>\n",
       "      <td>0.689448</td>\n",
       "      <td>0.097785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>0.097785</td>\n",
       "      <td>0.097785</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>0.902215</td>\n",
       "      <td>0.854133</td>\n",
       "      <td>0.097785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.097785</td>\n",
       "      <td>0.097785</td>\n",
       "      <td>0.021614</td>\n",
       "      <td>0.902215</td>\n",
       "      <td>0.844691</td>\n",
       "      <td>0.097785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.092382</td>\n",
       "      <td>0.092382</td>\n",
       "      <td>0.125375</td>\n",
       "      <td>0.907618</td>\n",
       "      <td>0.638482</td>\n",
       "      <td>0.092382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.089681</td>\n",
       "      <td>0.089681</td>\n",
       "      <td>0.088977</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>0.655907</td>\n",
       "      <td>0.089681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>0.084819</td>\n",
       "      <td>0.084819</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>0.915181</td>\n",
       "      <td>0.577771</td>\n",
       "      <td>0.084819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.915721</td>\n",
       "      <td>0.802269</td>\n",
       "      <td>0.084279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.082658</td>\n",
       "      <td>0.082658</td>\n",
       "      <td>0.063002</td>\n",
       "      <td>0.917342</td>\n",
       "      <td>0.655600</td>\n",
       "      <td>0.082658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.076175</td>\n",
       "      <td>0.076175</td>\n",
       "      <td>0.010633</td>\n",
       "      <td>0.923825</td>\n",
       "      <td>0.628764</td>\n",
       "      <td>0.076175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>0.055646</td>\n",
       "      <td>0.055646</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.944354</td>\n",
       "      <td>0.640939</td>\n",
       "      <td>0.055646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>0.043220</td>\n",
       "      <td>0.043220</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.956780</td>\n",
       "      <td>0.630393</td>\n",
       "      <td>0.043220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>0.042139</td>\n",
       "      <td>0.042139</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.957861</td>\n",
       "      <td>0.548137</td>\n",
       "      <td>0.042139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>0.037817</td>\n",
       "      <td>0.037817</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.962183</td>\n",
       "      <td>0.669519</td>\n",
       "      <td>0.037817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>0.037277</td>\n",
       "      <td>0.037277</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.763751</td>\n",
       "      <td>0.037277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.032955</td>\n",
       "      <td>0.032955</td>\n",
       "      <td>0.018586</td>\n",
       "      <td>0.967045</td>\n",
       "      <td>0.066639</td>\n",
       "      <td>0.032955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>0.032415</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.967585</td>\n",
       "      <td>0.854404</td>\n",
       "      <td>0.032415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.030254</td>\n",
       "      <td>0.030254</td>\n",
       "      <td>0.009674</td>\n",
       "      <td>0.969746</td>\n",
       "      <td>0.696362</td>\n",
       "      <td>0.030254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.029714</td>\n",
       "      <td>0.029714</td>\n",
       "      <td>0.013759</td>\n",
       "      <td>0.970286</td>\n",
       "      <td>0.065121</td>\n",
       "      <td>0.029714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>0.029173</td>\n",
       "      <td>0.029173</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.970827</td>\n",
       "      <td>0.802269</td>\n",
       "      <td>0.029173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.029173</td>\n",
       "      <td>0.029173</td>\n",
       "      <td>0.018840</td>\n",
       "      <td>0.970827</td>\n",
       "      <td>0.487209</td>\n",
       "      <td>0.029173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>0.026472</td>\n",
       "      <td>0.026472</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>0.973528</td>\n",
       "      <td>0.931224</td>\n",
       "      <td>0.026472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.022690</td>\n",
       "      <td>0.022690</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>0.977310</td>\n",
       "      <td>0.693970</td>\n",
       "      <td>0.022690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.978930</td>\n",
       "      <td>0.056702</td>\n",
       "      <td>0.021070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.980011</td>\n",
       "      <td>0.409542</td>\n",
       "      <td>0.019989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>0.980011</td>\n",
       "      <td>0.829194</td>\n",
       "      <td>0.019989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.019449</td>\n",
       "      <td>0.019449</td>\n",
       "      <td>0.009358</td>\n",
       "      <td>0.980551</td>\n",
       "      <td>0.642304</td>\n",
       "      <td>0.019449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.017288</td>\n",
       "      <td>0.017288</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>0.531944</td>\n",
       "      <td>0.017288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.017288</td>\n",
       "      <td>0.017288</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>0.512295</td>\n",
       "      <td>0.017288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>0.017288</td>\n",
       "      <td>0.017288</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>0.444240</td>\n",
       "      <td>0.017288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.984333</td>\n",
       "      <td>0.522767</td>\n",
       "      <td>0.015667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.015667</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.984333</td>\n",
       "      <td>0.946515</td>\n",
       "      <td>0.015667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.984873</td>\n",
       "      <td>0.534158</td>\n",
       "      <td>0.015127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>0.014046</td>\n",
       "      <td>0.014046</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.985954</td>\n",
       "      <td>0.744964</td>\n",
       "      <td>0.014046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.013506</td>\n",
       "      <td>0.013506</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.986494</td>\n",
       "      <td>0.489188</td>\n",
       "      <td>0.013506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.010805</td>\n",
       "      <td>0.010805</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.989195</td>\n",
       "      <td>0.655939</td>\n",
       "      <td>0.010805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.010265</td>\n",
       "      <td>0.010265</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.989735</td>\n",
       "      <td>0.139144</td>\n",
       "      <td>0.010265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>0.009184</td>\n",
       "      <td>0.009184</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.990816</td>\n",
       "      <td>0.426205</td>\n",
       "      <td>0.009184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>0.007023</td>\n",
       "      <td>0.007023</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.992977</td>\n",
       "      <td>0.337856</td>\n",
       "      <td>0.007023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>0.995138</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.004862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.995138</td>\n",
       "      <td>0.230416</td>\n",
       "      <td>0.004862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.995678</td>\n",
       "      <td>0.808012</td>\n",
       "      <td>0.004322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.995678</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.004322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.998379</td>\n",
       "      <td>0.343830</td>\n",
       "      <td>0.001621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.998920</td>\n",
       "      <td>0.816393</td>\n",
       "      <td>0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.999460</td>\n",
       "      <td>0.802269</td>\n",
       "      <td>0.000540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     K  Accuracy  F1 Micro Average  F1 Macro Average  Hamming Loss  Precision  \\\n",
       "0    1  0.802269          0.802269          0.445144      0.197731   0.643636   \n",
       "1    2  0.718531          0.718531          0.562240      0.281469   0.722266   \n",
       "3    4  0.678012          0.678012          0.367040      0.321988   0.728120   \n",
       "10  11  0.588871          0.588871          0.151680      0.411129   0.726549   \n",
       "9   10  0.573204          0.573204          0.136907      0.426796   0.717389   \n",
       "30  31  0.320367          0.320367          0.038904      0.679633   0.700796   \n",
       "17  18  0.243112          0.243112          0.061993      0.756888   0.842545   \n",
       "6    7  0.172880          0.172880          0.079071      0.827120   0.606959   \n",
       "20  21  0.139384          0.139384          0.024917      0.860616   0.794527   \n",
       "12  13  0.121556          0.121556          0.039764      0.878444   0.653498   \n",
       "4    5  0.119395          0.119395          0.052494      0.880605   0.033155   \n",
       "7    8  0.109130          0.109130          0.079938      0.890870   0.638256   \n",
       "31  32  0.097785          0.097785          0.018511      0.902215   0.689448   \n",
       "38  39  0.097785          0.097785          0.014251      0.902215   0.854133   \n",
       "21  22  0.097785          0.097785          0.021614      0.902215   0.844691   \n",
       "2    3  0.092382          0.092382          0.125375      0.907618   0.638482   \n",
       "5    6  0.089681          0.089681          0.088977      0.910319   0.655907   \n",
       "45  46  0.084819          0.084819          0.012072      0.915181   0.577771   \n",
       "36  37  0.084279          0.084279          0.008642      0.915721   0.802269   \n",
       "8    9  0.082658          0.082658          0.063002      0.917342   0.655600   \n",
       "25  26  0.076175          0.076175          0.010633      0.923825   0.628764   \n",
       "37  38  0.055646          0.055646          0.006600      0.944354   0.640939   \n",
       "43  44  0.043220          0.043220          0.005654      0.956780   0.630393   \n",
       "54  55  0.042139          0.042139          0.004342      0.957861   0.548137   \n",
       "40  41  0.037817          0.037817          0.004501      0.962183   0.669519   \n",
       "39  40  0.037277          0.037277          0.005854      0.962723   0.763751   \n",
       "19  20  0.032955          0.032955          0.018586      0.967045   0.066639   \n",
       "49  50  0.032415          0.032415          0.006383      0.967585   0.854404   \n",
       "29  30  0.030254          0.030254          0.009674      0.969746   0.696362   \n",
       "26  27  0.029714          0.029714          0.013759      0.970286   0.065121   \n",
       "41  42  0.029173          0.029173          0.003190      0.970827   0.802269   \n",
       "16  17  0.029173          0.029173          0.018840      0.970827   0.487209   \n",
       "53  54  0.026472          0.026472          0.006103      0.973528   0.931224   \n",
       "18  19  0.022690          0.022690          0.010626      0.977310   0.693970   \n",
       "27  28  0.021070          0.021070          0.010359      0.978930   0.056702   \n",
       "55  56  0.019989          0.019989          0.004464      0.980011   0.409542   \n",
       "50  51  0.019989          0.019989          0.004066      0.980011   0.829194   \n",
       "13  14  0.019449          0.019449          0.009358      0.980551   0.642304   \n",
       "14  15  0.017288          0.017288          0.008142      0.982712   0.531944   \n",
       "11  12  0.017288          0.017288          0.013734      0.982712   0.512295   \n",
       "57  58  0.017288          0.017288          0.002193      0.982712   0.444240   \n",
       "52  53  0.015667          0.015667          0.001910      0.984333   0.522767   \n",
       "47  48  0.015667          0.015667          0.001631      0.984333   0.946515   \n",
       "15  16  0.015127          0.015127          0.006645      0.984873   0.534158   \n",
       "56  57  0.014046          0.014046          0.001322      0.985954   0.744964   \n",
       "24  25  0.013506          0.013506          0.002340      0.986494   0.489188   \n",
       "22  23  0.010805          0.010805          0.002658      0.989195   0.655939   \n",
       "28  29  0.010265          0.010265          0.006043      0.989735   0.139144   \n",
       "44  45  0.009184          0.009184          0.001019      0.990816   0.426205   \n",
       "48  49  0.007023          0.007023          0.001045      0.992977   0.337856   \n",
       "35  36  0.004862          0.004862          0.001383      0.995138   0.808000   \n",
       "34  35  0.004862          0.004862          0.000755      0.995138   0.230416   \n",
       "51  52  0.004322          0.004322          0.000939      0.995678   0.808012   \n",
       "33  34  0.004322          0.004322          0.001200      0.995678   0.004708   \n",
       "42  43  0.001621          0.001621          0.000175      0.998379   0.343830   \n",
       "23  24  0.001080          0.001080          0.000441      0.998920   0.816393   \n",
       "58  59  0.000540          0.000540          0.000042      0.999460   0.802269   \n",
       "46  47  0.000000          0.000000          0.000000      1.000000   0.000000   \n",
       "32  33  0.000000          0.000000          0.000000      1.000000   0.000000   \n",
       "\n",
       "      Recall  \n",
       "0   0.802269  \n",
       "1   0.718531  \n",
       "3   0.678012  \n",
       "10  0.588871  \n",
       "9   0.573204  \n",
       "30  0.320367  \n",
       "17  0.243112  \n",
       "6   0.172880  \n",
       "20  0.139384  \n",
       "12  0.121556  \n",
       "4   0.119395  \n",
       "7   0.109130  \n",
       "31  0.097785  \n",
       "38  0.097785  \n",
       "21  0.097785  \n",
       "2   0.092382  \n",
       "5   0.089681  \n",
       "45  0.084819  \n",
       "36  0.084279  \n",
       "8   0.082658  \n",
       "25  0.076175  \n",
       "37  0.055646  \n",
       "43  0.043220  \n",
       "54  0.042139  \n",
       "40  0.037817  \n",
       "39  0.037277  \n",
       "19  0.032955  \n",
       "49  0.032415  \n",
       "29  0.030254  \n",
       "26  0.029714  \n",
       "41  0.029173  \n",
       "16  0.029173  \n",
       "53  0.026472  \n",
       "18  0.022690  \n",
       "27  0.021070  \n",
       "55  0.019989  \n",
       "50  0.019989  \n",
       "13  0.019449  \n",
       "14  0.017288  \n",
       "11  0.017288  \n",
       "57  0.017288  \n",
       "52  0.015667  \n",
       "47  0.015667  \n",
       "15  0.015127  \n",
       "56  0.014046  \n",
       "24  0.013506  \n",
       "22  0.010805  \n",
       "28  0.010265  \n",
       "44  0.009184  \n",
       "48  0.007023  \n",
       "35  0.004862  \n",
       "34  0.004862  \n",
       "51  0.004322  \n",
       "33  0.004322  \n",
       "42  0.001621  \n",
       "23  0.001080  \n",
       "58  0.000540  \n",
       "46  0.000000  \n",
       "32  0.000000  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame (count_val_scores)\n",
    "scores_df.sort_values ('Recall', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e03aeae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = count_models [1].predict (count_val)\n",
    "val_labeled_df = val_df.copy() \n",
    "val_labeled_df ['predictions'] = val_predictions \n",
    "val_labeled_df ['predictions'] = val_labeled_df ['predictions'].replace(count_val_scores [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e9236fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K': 2,\n",
       " 'Accuracy': 0.7185305240410589,\n",
       " 'F1 Micro Average': 0.7185305240410589,\n",
       " 'F1 Macro Average': 0.5622395271826833,\n",
       " 'Hamming Loss': 0.2814694759589411,\n",
       " 'Precision': 0.7222663991485183,\n",
       " 'Recall': 0.7185305240410589}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_scores = format_scores (2, val_labeled_df ['label'], val_labeled_df ['predictions'])\n",
    "dict_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0695bf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = count_models [1].predict (count_test)\n",
    "test_labeled_df = test_df.copy() \n",
    "test_labeled_df ['predictions'] = test_predictions \n",
    "test_labeled_df ['predictions'] = test_labeled_df ['predictions'].replace(count_labels_per_cluster [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb2f3f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K': 2,\n",
       " 'Accuracy': 0.7279014480224768,\n",
       " 'F1 Micro Average': 0.7279014480224768,\n",
       " 'F1 Macro Average': 0.5656434064829965,\n",
       " 'Hamming Loss': 0.27209855197752325,\n",
       " 'Precision': 0.7241807889524337,\n",
       " 'Recall': 0.7279014480224768}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_scores = format_scores (2, test_labeled_df ['label'], test_labeled_df ['predictions'])\n",
    "dict_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0900894e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x222cbdd4640>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(test_labeled_df ['label'], test_labeled_df ['predictions'])).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13ac617",
   "metadata": {},
   "source": [
    "## K-means and Logistic Regression (TF-IDF Vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "54be5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logreg_models = []\n",
    "tfidf_logreg_km_models = []\n",
    "tfidf_logreg_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7b11a50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "for k in range (1, 60):\n",
    "    logreg_model = LogisticRegression ()\n",
    "    val_score, km, model = cluster_then_categorize_news (k, count_train, count_val, logreg_model, tfidf_vectorizer)\n",
    "    tfidf_logreg_scores.append (val_score)\n",
    "    tfidf_logreg_models.append (model)\n",
    "    tfidf_logreg_km_models.append (km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "54a8dd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'K': 1,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 2,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 3,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 4,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 5,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 6,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 7,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 8,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 9,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 10,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 11,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 12,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 13,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 14,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 15,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 16,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 17,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 18,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 19,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 20,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 21,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 22,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 23,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 24,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 25,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 26,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 27,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 28,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 29,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 30,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 31,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 32,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 33,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 34,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 35,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 36,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 37,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 38,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 39,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 40,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 41,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 42,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 43,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 44,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 45,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 46,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 47,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 48,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 49,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 50,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 51,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 52,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 53,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 54,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 55,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 56,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 57,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 58,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589},\n",
       " {'K': 59,\n",
       "  'Accuracy': 0.7185305240410589,\n",
       "  'F1 Micro Average': 0.7185305240410589,\n",
       "  'F1 Macro Average': 0.5622395271826833,\n",
       "  'Hamming Loss': 0.2814694759589411,\n",
       "  'Precision': 0.7222663991485183,\n",
       "  'Recall': 0.7185305240410589}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_logreg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b50f07a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Micro Average</th>\n",
       "      <th>F1 Macro Average</th>\n",
       "      <th>Hamming Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>51</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>53</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>56</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>58</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.56224</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.722266</td>\n",
       "      <td>0.718531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     K  Accuracy  F1 Micro Average  F1 Macro Average  Hamming Loss  Precision  \\\n",
       "0    1  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "44  45  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "32  33  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "33  34  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "34  35  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "35  36  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "36  37  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "37  38  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "38  39  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "39  40  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "40  41  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "41  42  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "42  43  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "43  44  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "45  46  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "30  31  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "46  47  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "47  48  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "48  49  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "49  50  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "50  51  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "51  52  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "52  53  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "53  54  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "54  55  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "55  56  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "56  57  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "57  58  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "31  32  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "29  30  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "1    2  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "14  15  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "2    3  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "3    4  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "4    5  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "5    6  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "6    7  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "7    8  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "8    9  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "9   10  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "10  11  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "11  12  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "12  13  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "13  14  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "15  16  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "28  29  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "16  17  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "17  18  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "18  19  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "19  20  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "20  21  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "21  22  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "22  23  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "23  24  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "24  25  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "25  26  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "26  27  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "27  28  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "58  59  0.718531          0.718531           0.56224      0.281469   0.722266   \n",
       "\n",
       "      Recall  \n",
       "0   0.718531  \n",
       "44  0.718531  \n",
       "32  0.718531  \n",
       "33  0.718531  \n",
       "34  0.718531  \n",
       "35  0.718531  \n",
       "36  0.718531  \n",
       "37  0.718531  \n",
       "38  0.718531  \n",
       "39  0.718531  \n",
       "40  0.718531  \n",
       "41  0.718531  \n",
       "42  0.718531  \n",
       "43  0.718531  \n",
       "45  0.718531  \n",
       "30  0.718531  \n",
       "46  0.718531  \n",
       "47  0.718531  \n",
       "48  0.718531  \n",
       "49  0.718531  \n",
       "50  0.718531  \n",
       "51  0.718531  \n",
       "52  0.718531  \n",
       "53  0.718531  \n",
       "54  0.718531  \n",
       "55  0.718531  \n",
       "56  0.718531  \n",
       "57  0.718531  \n",
       "31  0.718531  \n",
       "29  0.718531  \n",
       "1   0.718531  \n",
       "14  0.718531  \n",
       "2   0.718531  \n",
       "3   0.718531  \n",
       "4   0.718531  \n",
       "5   0.718531  \n",
       "6   0.718531  \n",
       "7   0.718531  \n",
       "8   0.718531  \n",
       "9   0.718531  \n",
       "10  0.718531  \n",
       "11  0.718531  \n",
       "12  0.718531  \n",
       "13  0.718531  \n",
       "15  0.718531  \n",
       "28  0.718531  \n",
       "16  0.718531  \n",
       "17  0.718531  \n",
       "18  0.718531  \n",
       "19  0.718531  \n",
       "20  0.718531  \n",
       "21  0.718531  \n",
       "22  0.718531  \n",
       "23  0.718531  \n",
       "24  0.718531  \n",
       "25  0.718531  \n",
       "26  0.718531  \n",
       "27  0.718531  \n",
       "58  0.718531  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame (tfidf_logreg_scores)\n",
    "scores_df.sort_values ('Recall', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = tfidf_logreg_models [1].predict (count_test)\n",
    "test_labeled_df = test_df.copy() \n",
    "test_labeled_df ['predictions'] = test_predictions \n",
    "test_labeled_df ['predictions'] = test_labeled_df ['predictions'].replace(count_labels_per_cluster [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fe6ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = format_scores (2, test_labeled_df ['label'], test_labeled_df ['predictions'])\n",
    "dict_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7dca53cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x222cbff45e0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay(confusion_matrix(test_labeled_df ['label'], test_labeled_df ['predictions'])).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
