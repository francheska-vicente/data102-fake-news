{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3058ede7",
   "metadata": {},
   "source": [
    "# **Tsimis Yarn?**: Identifying Fake News Among the News Articles Online\n",
    "\n",
    "## **Introduction**\n",
    "In the age of digital media and information, false information, especially, fake news can now be easily disseminated across the globe. The potential damage that could be inflicted by fake news can be serious as news could travel more quickly now through social media platform, especially sensational stories that disinformation producers often manipulate to sell fake news (Siar, 2021). The consequences of dissemination of fake news could go far and wide as **disseminating misleading or fabricated news articles can have significant impact on public opinion, social discourse, and even democratic processes**. \n",
    "\n",
    "A new Pulse Asia survey revealed that about <u>9 out of 10 Filipino adults perceive the widespread dissemination of “fake news” as a problem</u> within the country (Lalu, 2022). According to another poll, **58% of Filipinos view social media influencers, bloggers and vloggers** as peddlers of fake news about government and politics, followed by **journalists at 40%**, **national politicians at 37%** and **local politicians at 30%** (Gregorio, 2022). This underscores the continued <u>threat to Philippine press freedom</u> posed by disinformation and fake news that persistently spread and mislead the people, especially Filipinos (Casayuran, 2023).\n",
    "\n",
    "Now, this project is rooted from the urgent need to address the widespread dissemination of fake news in today’s society, especially in the Philippines. As there is evidently a need for effective tools and techniques to identify and combat fake news, this project will focus on creating a model for fake news detection. In this project, **classification and clustering algorithms** would be applied for building the detection model. Through these algorithms, **differentiating fake news from real news** will be performed by the model and utilize this as its <u>knowledge to identify fake news</u> in online texts.\n",
    "\n",
    "By developing and implementing reliable fake news detection algorithms, we can **empower individuals, social media platforms, press media freedom, and news organizations to identify and combat misinformation effectively**. \n",
    "\n",
    "## **Authors:**\n",
    "- Banzon, Beatrice Elaine B.\n",
    "- Buitre, Cameron\n",
    "- Marcelo, Andrea Jean C.\n",
    "- Navarro, Alyssa Riantha R.\n",
    "- Vicente, Francheska Josefa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb937d43",
   "metadata": {},
   "source": [
    "# Imports and Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc693a71",
   "metadata": {},
   "source": [
    "## `Basic` Libraries\n",
    "\n",
    "- [`numpy`](https://numpy.org) contains a large collection of mathematical functions\n",
    "- [`pandas`](https://pandas.pydata.org) contains functions that are designed for data manipulation and data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "08df81d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed38742f",
   "metadata": {},
   "source": [
    "## `Visualization` Libraries\n",
    "\n",
    "- [`matplotlib.pyplot`](https://matplotlib.org/3.5.3/api/afm_api.html) contains functions to create interactive plots\n",
    "- [`seaborn`](https://seaborn.pydata.org/index.html) is a library based on matplotlib that allows for data visualization\n",
    "- [`spacy`](https://spacy.io) is a Python-based open-source library used in processing text data.\n",
    "- [`wordcloud`](https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html) contains functions for generating wordclouds from text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "84a15091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import ImageColorGenerator\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b999c",
   "metadata": {},
   "source": [
    "## [`Natural Language Processing`](https://www.nltk.org/index.html) Libraries\n",
    "\n",
    "- [`re`](https://www.nltk.org/api/nltk.chunk.regexp.html?highlight=import+re) is a module that allows the use of regular expressions\n",
    "- [`nltk`](https://www.nltk.org/install.html?highlight=import+re) contains various tools and modules for natural language processing.\n",
    "- [`stopwords`](https://www.nltk.org/howto/corpus.html?highlight=stopwords)  is a corpus from NLTK, which contains common words that are often removed during text processing as they don't carry significant meaning\n",
    "- [`words`](https://www.nltk.org/howto/corpus.html?highlight=words) is a corpus from NLTK which contains English words that are often used for identifying English texts\n",
    "- [`WordNetLemmatizer()`](https://www.nltk.org/api/nltk.stem.WordNetLemmatizer.html?highlight=wordnetlemmatizer) is used for word lemmatization (converting words to their base or dictionary form).\n",
    "- [`RegexpTokenizer`](https://www.nltk.org/api/nltk.tokenize.regexp.html) class from nltk, which is used for tokenizing text based on regular expressions.\n",
    "- [`wordpunct_tokenize`](https://www.nltk.org/api/nltk.tokenize.wordpunct_tokenize.html?highlight=wordpunct_tokenize#nltk.tokenize.wordpunct_tokenize) function from nltk, which is used for tokenizing text into words.\n",
    "- [`FreqDist`](https://www.nltk.org/api/nltk.probability.FreqDist.html?highlight=freqdist)[`FreqDist class`] from nltk.probability, which is used to compute the frequency distribution of words in a text.\n",
    "- [`SentimentIntensityAnalyzer`](https://www.nltk.org/api/nltk.sentiment.SentimentIntensityAnalyzer.html?highlight=sentimentintensityanalyzer#nltk.sentiment.SentimentIntensityAnalyzer) class from nltk.sentiment, which is used for sentiment analysis of text.\n",
    "-  [`ngrams`](https://www.nltk.org/api/nltk.util.html?highlight=ngrams#nltk.util.ngrams)function from nltk, which is used for generating n-grams (contiguous sequences of n words) from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "2acfba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# Load the English words corpus from NLTK\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import download, classify, corpus\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "d53630cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ajmarcelo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/ajmarcelo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ajmarcelo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/ajmarcelo/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/ajmarcelo/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/ajmarcelo/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "c6efd482",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "7eeb2d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0049d70f",
   "metadata": {},
   "source": [
    "## `News Dataset` Files\n",
    "The following **`.csv`** files will be used in this project:\n",
    "### Retrieved from <u>Web Scraping</u>\n",
    "- `rap_dataframe.csv` - this contains the articles scraped form the **Rappler** website. The following are its columns: <u>article content</u>, <u>author</u>, and <u>link</u>.\n",
    "- `gma_dataframe.csv` and `gma-10000.csv` - these contain the content of the <u>article content</u>, <u>author</u>, and <u>link</u> that is scraped from the **GMA website**.\n",
    "- `fake news dataset.csv`- This handles the articles that were retrieved from web scraping fake news sites, **Ako'y Pilipino** and **Maharlika News**. This contains two columns wherein one represents the article <u>Content</u> and the other represents its <u>label</u> (0 or 1).\n",
    "### Retrieved from <u>Kaggle</u>\n",
    "- `fake_or_real_news.csv` - this data is retrieved from **[Fake or Real News](https://www.kaggle.com/datasets/jillanisofttech/fake-or-real-news)** in **Kaggle** which contains the following column: article <u>number</u>,<u>title</u>, <u>text</u> (represents content), and <u>label</u> (REAL or FAKE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f518d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preprocessing\n",
    "<u>**`Importing Dataset`</u>**<br>\n",
    "After importing all the necessary libraries that we would need, we will now **import the different `.csv` files** we retrieved from different sources into the notebook using the [`read_csv()`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). \n",
    "\n",
    "To add, the [`head()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html?highlight=head#pandas.DataFrame.head) function will also be used to check the <u>first few rows</u> of the each imported data. This will let us have a glance on the **features of each dataset** and what **type of data each feature** has.\n",
    "\n",
    "<u>**`Dataset Description`</u>**<br>\n",
    "Also, to get to know more about each dataset the [`info`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html?highlight=info#pandas.DataFrame.info) function will be used. This function provides information about a DataFrame including the  shape, data type of each columns, non-null values count, and memory usage.\n",
    "\n",
    "<u>**`Fixing The Imported Dataset Structure for Data Combination`**</u><br>\n",
    "After this, we will be <u>fixing each dataset format</u> before combining all of the news data together in one dataset. While formatting the imported datasets, we aim to get the content of each collected article for the data combination later on. With this,we will have to attach a `label` column to these datasets. The `label` will become the indicator of each article whether the article is real or fake news.\n",
    "\n",
    "<u>**`Outcome of Data Preprocessing`**</u><br>\n",
    "Finishing this section will result to a dataset with two columns: `label` and `Content`. \n",
    "> The `Content` column which contains all of the **article content** from the collected data, **both** fake and real news. \n",
    "\n",
    "> The `label` column which contains the article label **\"0\" to signify real** news and **\"1\" to represent fake** news. This column will let us identify the article type of each data despite being combined in one dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc04889",
   "metadata": {},
   "source": [
    "## **`Real News`** Data\n",
    "For our **real news data**, we have scraped <u>two sets of news data</u>. One set is from the **[`Rappler`](https://www.rappler.com/)** website and the other is from the **[`GMA News`](https://www.gmanetwork.com/news/topstories/)** website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157ee61",
   "metadata": {},
   "source": [
    "### **`Rappler`** Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290cc7e8",
   "metadata": {},
   "source": [
    "First, we will be loading the Rappler news (**`rap_dataframe.csv`**) data using the [`read_csv()`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) and store it into a DataFrame named `df_Rappler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "d858b4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.rappler.com/life-and-style/literat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.rappler.com/nation/new-findings-ki...</td>\n",
       "      <td>['JAIRO BOLLEDO']</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.rappler.com/sports/football/tom-br...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.rappler.com/life-and-style/health-...</td>\n",
       "      <td>[]</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.rappler.com/entertainment/music/ju...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link             Author  \\\n",
       "0  https://www.rappler.com/life-and-style/literat...                 []   \n",
       "1  https://www.rappler.com/nation/new-findings-ki...  ['JAIRO BOLLEDO']   \n",
       "2  https://www.rappler.com/sports/football/tom-br...                 []   \n",
       "3  https://www.rappler.com/life-and-style/health-...                 []   \n",
       "4  https://www.rappler.com/entertainment/music/ju...                 []   \n",
       "\n",
       "                                             Content  \n",
       "0  MANILA, Philippines – Finally! Best-selling Ja...  \n",
       "1  MANILA, Philippines – The results of the lates...  \n",
       "2  Tom Brady was the ultimate winner on the field...  \n",
       "3  It’s one thing to know what makes people happy...  \n",
       "4  Justin Bieber is the latest artist in a growin...  "
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_Rappler` : contains the collected real news data from Rappler\n",
    "\n",
    "df_Rappler = pd.read_csv('data/rap_dataframe.csv')\n",
    "df_Rappler.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817aaeb9-1f13-4d51-ac8c-45390b1b737f",
   "metadata": {},
   "source": [
    "#### Dataset Description\n",
    "\n",
    "Using the [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html), let us view the description of the Rappler data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "b011c6b5-c8de-4184-b707-b4bcddf0bc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1202 entries, 0 to 1201\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Link     1202 non-null   object\n",
      " 1   Author   1202 non-null   object\n",
      " 2   Content  1201 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 28.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# `df_Rappler` : contains the collected real news data from Rappler\n",
    "\n",
    "df_Rappler.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab81bb-561e-4bd7-adc9-f7af5d21a2cd",
   "metadata": {},
   "source": [
    "From this, we can see that there are **1202 articles (rows)** and **3 columns** for this dataset. However, there is a *one null value* in the `Content` column as the output states that the column has <u>1201 non-null values out of 1202 articles</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cb5c89-5581-44c9-9455-3182e7dfa739",
   "metadata": {},
   "source": [
    "#### Fixing the Dataset Structure\n",
    "\n",
    "##### **`Dropping Columns`**\n",
    "As seen in the output above, the Rappler data has 3 columns: `Link`, `Author`, `Content`. Since we will only be needing the `Content` column of this dataset, which represents each article's content, we will only be retrieving this column. With this, we will use the [`drop()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html?highlight=drop#pandas.DataFrame.drop) to drop the `Link` and `Author` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "eb05681a-f4bb-4a96-95c8-e0dac45efbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>MANILA, Philippines – Thai businesswoman and C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>BEIJING, China – Luggage-laden passengers floc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>Kawhi Leonard and Terance Mann each eclipsed 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>Nikola Vucevic continued his recent dominance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>White terror, suppression of media and free sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1202 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Content\n",
       "0     MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1     MANILA, Philippines – The results of the lates...\n",
       "2     Tom Brady was the ultimate winner on the field...\n",
       "3     It’s one thing to know what makes people happy...\n",
       "4     Justin Bieber is the latest artist in a growin...\n",
       "...                                                 ...\n",
       "1197  MANILA, Philippines – Thai businesswoman and C...\n",
       "1198  BEIJING, China – Luggage-laden passengers floc...\n",
       "1199  Kawhi Leonard and Terance Mann each eclipsed 3...\n",
       "1200  Nikola Vucevic continued his recent dominance ...\n",
       "1201  White terror, suppression of media and free sp...\n",
       "\n",
       "[1202 rows x 1 columns]"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_Rappler` : contains the collected real news data from Rappler\n",
    "\n",
    "# Drops the `Link` and `Author` columns to only have the Content column of the Rappler Data \n",
    "df_Rappler.drop([\"Link\", \"Author\"], axis=1, inplace=True)\n",
    "\n",
    "df_Rappler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e78f11-8799-4397-b0f0-58fb8336cea8",
   "metadata": {},
   "source": [
    "##### **`Adding the \"label\" Column`**\n",
    "After retrieving only the `Content` column, we will now attach a `label` column **set each row to `0`** since all of the collected data from Rappler are real news. To recall, in this project, a `0` value in `label` column means it is a real news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "1aff6331-772e-4d92-a1ce-a1b96d764c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>MANILA, Philippines – Thai businesswoman and C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>BEIJING, China – Luggage-laden passengers floc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>Kawhi Leonard and Terance Mann each eclipsed 3...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>Nikola Vucevic continued his recent dominance ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>White terror, suppression of media and free sp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Content  label\n",
       "0     MANILA, Philippines – Finally! Best-selling Ja...      0\n",
       "1     MANILA, Philippines – The results of the lates...      0\n",
       "2     Tom Brady was the ultimate winner on the field...      0\n",
       "3     It’s one thing to know what makes people happy...      0\n",
       "4     Justin Bieber is the latest artist in a growin...      0\n",
       "...                                                 ...    ...\n",
       "1197  MANILA, Philippines – Thai businesswoman and C...      0\n",
       "1198  BEIJING, China – Luggage-laden passengers floc...      0\n",
       "1199  Kawhi Leonard and Terance Mann each eclipsed 3...      0\n",
       "1200  Nikola Vucevic continued his recent dominance ...      0\n",
       "1201  White terror, suppression of media and free sp...      0\n",
       "\n",
       "[1202 rows x 2 columns]"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_Rappler` : contains the collected real news data from Rappler\n",
    "\n",
    "# Adding a label column to the new dataframe\n",
    "df_Rappler['label'] = 0\n",
    "\n",
    "df_Rappler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c34f0d-e611-4576-96f3-0adaf0868a3d",
   "metadata": {},
   "source": [
    "##### **`Rearranging Columns`**\n",
    "Next, let us rearrange the columns wherein the `label` column is the first column of the dataset. This is to give way for other article data that could be added to the dataset in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "30be506d-1c40-4ddd-ab8a-9124d7ae3be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Thai businesswoman and C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>0</td>\n",
       "      <td>BEIJING, China – Luggage-laden passengers floc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>0</td>\n",
       "      <td>Kawhi Leonard and Terance Mann each eclipsed 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>0</td>\n",
       "      <td>Nikola Vucevic continued his recent dominance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>0</td>\n",
       "      <td>White terror, suppression of media and free sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1202 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            Content\n",
       "0         0  MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1         0  MANILA, Philippines – The results of the lates...\n",
       "2         0  Tom Brady was the ultimate winner on the field...\n",
       "3         0  It’s one thing to know what makes people happy...\n",
       "4         0  Justin Bieber is the latest artist in a growin...\n",
       "...     ...                                                ...\n",
       "1197      0  MANILA, Philippines – Thai businesswoman and C...\n",
       "1198      0  BEIJING, China – Luggage-laden passengers floc...\n",
       "1199      0  Kawhi Leonard and Terance Mann each eclipsed 3...\n",
       "1200      0  Nikola Vucevic continued his recent dominance ...\n",
       "1201      0  White terror, suppression of media and free sp...\n",
       "\n",
       "[1202 rows x 2 columns]"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_Rappler` : contains the collected real news data from Rappler\n",
    "df_Rappler = df_Rappler[['label', 'Content']]\n",
    "\n",
    "df_Rappler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24faca05-0315-432c-bcfd-438819e82dbb",
   "metadata": {},
   "source": [
    "Now that the Rappler news data has the `Content` and the `label` columns only and is in order, we can now recheck the updated dataset description for the Rappler data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b53922c-2729-45c0-93ea-fe11a9a7fec5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Final Dataset Description\n",
    "After fixing the Rappler dataset, let us check its updated dataset information through [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html). \n",
    "\n",
    "This is to also check if there are any null values on the `label`. If there is a null value under the `label` column, this will be automatically filled up by a `0` value to indicate that its equivalent article content is a real news. This is possible since the news from Rappler are all real news data.\n",
    "\n",
    "\n",
    "However, if the null values are only found in `Content` this will be not be removed for now and will be dropped later on once the combined real and fake news data will undergo data cleaning. This is to drop all article rows with null `Content` values all in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "01a4cdb4-736a-4688-adce-7d419067d333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1202 entries, 0 to 1201\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    1202 non-null   int64 \n",
      " 1   Content  1201 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_Rappler.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d429c0e-5cef-41d0-9858-060138ef704f",
   "metadata": {},
   "source": [
    "Now that we know that there are no null values under the `label` column of the Rappler data, we can now proceed to importing the next data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99cdf96",
   "metadata": {},
   "source": [
    "### **`GMA News`** Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677060ec",
   "metadata": {},
   "source": [
    "For our GMA Data, we scraped two data. These two data (**`gma_dataframe.csv`** and **`gma-10000.csv`**)will also be loaded using the [`read_csv()`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html), and stored into two separate DataFrames that we will be naming `df_gma1` and `df_gma2`. \n",
    "\n",
    "After this, we will concatenate the two GMA datasets and will be stored into a dataframe named `df_GMA`.\n",
    "\n",
    "Let us first import the data from **`gma-10000.csv`** and store it to `df_gma1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "e08ffd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Link</th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gmanetwork.com/news/balitambayan/p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Arestado ng Laguna Police ang isang elementary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.gmanetwork.com/news/topstories/reg...</td>\n",
       "      <td>['By GMA Integrated News']</td>\n",
       "      <td>A barangay kagawad was shot dead in front of b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.gmanetwork.com/news/topstories/wor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>GENEVA, Switzerland - Taliban restrictions on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.gmanetwork.com/news/topstories/nat...</td>\n",
       "      <td>['By GMA Integrated News']</td>\n",
       "      <td>The National Privacy Commission (NPC) has issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.gmanetwork.com/news/topstories/wor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>STOCKHOLM, Sweden - More than 600 young people...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Link  \\\n",
       "0           0  https://www.gmanetwork.com/news/balitambayan/p...   \n",
       "1           1  https://www.gmanetwork.com/news/topstories/reg...   \n",
       "2           2  https://www.gmanetwork.com/news/topstories/wor...   \n",
       "3           3  https://www.gmanetwork.com/news/topstories/nat...   \n",
       "4           4  https://www.gmanetwork.com/news/topstories/wor...   \n",
       "\n",
       "                       Author  \\\n",
       "0                          []   \n",
       "1  ['By GMA Integrated News']   \n",
       "2                          []   \n",
       "3  ['By GMA Integrated News']   \n",
       "4                          []   \n",
       "\n",
       "                                             Content  \n",
       "0  Arestado ng Laguna Police ang isang elementary...  \n",
       "1  A barangay kagawad was shot dead in front of b...  \n",
       "2  GENEVA, Switzerland - Taliban restrictions on ...  \n",
       "3  The National Privacy Commission (NPC) has issu...  \n",
       "4  STOCKHOLM, Sweden - More than 600 young people...  "
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_gma1` : contains the GMA news data from gma-10000.csv\n",
    "\n",
    "df_gma1 = pd.read_csv('data/gma-10000.csv')\n",
    "df_gma1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed972f6d-25a4-4716-9435-df41b420fba6",
   "metadata": {},
   "source": [
    "Next, let's import the data from **`gma_dataframe.csv`** and store it to `df_gma2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "9bf7529a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Link</th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.gmanetwork.com/news/topstories/wor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>BEIJING - China lashed out at the United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.gmanetwork.com/news/topstories/met...</td>\n",
       "      <td>['By GMA Integrated News']</td>\n",
       "      <td>Two people were arrested in Tondo, Manila for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.gmanetwork.com/news/topstories/nat...</td>\n",
       "      <td>['By JOVILAND RITA, GMA Integrated News']</td>\n",
       "      <td>Former Bureau of Corrections (BuCor) chief Ger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.gmanetwork.com/news/balitambayan/b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Dalawa katao ang arestado sa Tondo, Maynila da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.gmanetwork.com/news/balitambayan/p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NEW YORK CITY — Nasa 9,000 nurse na nagtatraba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Link  \\\n",
       "0  https://www.gmanetwork.com/news/topstories/wor...   \n",
       "1  https://www.gmanetwork.com/news/topstories/met...   \n",
       "2  https://www.gmanetwork.com/news/topstories/nat...   \n",
       "3  https://www.gmanetwork.com/news/balitambayan/b...   \n",
       "4  https://www.gmanetwork.com/news/balitambayan/p...   \n",
       "\n",
       "                                      Author  \\\n",
       "0                                         []   \n",
       "1                 ['By GMA Integrated News']   \n",
       "2  ['By JOVILAND RITA, GMA Integrated News']   \n",
       "3                                         []   \n",
       "4                                         []   \n",
       "\n",
       "                                             Content  \n",
       "0  BEIJING - China lashed out at the United State...  \n",
       "1  Two people were arrested in Tondo, Manila for ...  \n",
       "2  Former Bureau of Corrections (BuCor) chief Ger...  \n",
       "3  Dalawa katao ang arestado sa Tondo, Maynila da...  \n",
       "4  NEW YORK CITY — Nasa 9,000 nurse na nagtatraba...  "
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_gma2` : contains the GMA news data from gma_dataframe.csv\n",
    "\n",
    "df_gma2 = pd.read_csv('data/gma_dataframe.csv')\n",
    "df_gma2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288e8d4e",
   "metadata": {},
   "source": [
    "#### Combining the Two GMA Datasets\n",
    "After loading and storing it into two separate DataFrames, we will now be merging the two GMA news data together into one single DataFrame. \n",
    "\n",
    "Since both `df_gma1` and `df_gma2` have the same columns, we can combine the two datasets right away using [`concat()`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html?highlight=concat#pandas.concat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "06f5910e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Link</th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.gmanetwork.com/news/balitambayan/p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Arestado ng Laguna Police ang isang elementary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.gmanetwork.com/news/topstories/reg...</td>\n",
       "      <td>['By GMA Integrated News']</td>\n",
       "      <td>A barangay kagawad was shot dead in front of b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>https://www.gmanetwork.com/news/topstories/wor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>GENEVA, Switzerland - Taliban restrictions on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>https://www.gmanetwork.com/news/topstories/nat...</td>\n",
       "      <td>['By GMA Integrated News']</td>\n",
       "      <td>The National Privacy Commission (NPC) has issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.gmanetwork.com/news/topstories/wor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>STOCKHOLM, Sweden - More than 600 young people...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Link  \\\n",
       "0         0.0  https://www.gmanetwork.com/news/balitambayan/p...   \n",
       "1         1.0  https://www.gmanetwork.com/news/topstories/reg...   \n",
       "2         2.0  https://www.gmanetwork.com/news/topstories/wor...   \n",
       "3         3.0  https://www.gmanetwork.com/news/topstories/nat...   \n",
       "4         4.0  https://www.gmanetwork.com/news/topstories/wor...   \n",
       "\n",
       "                       Author  \\\n",
       "0                          []   \n",
       "1  ['By GMA Integrated News']   \n",
       "2                          []   \n",
       "3  ['By GMA Integrated News']   \n",
       "4                          []   \n",
       "\n",
       "                                             Content  \n",
       "0  Arestado ng Laguna Police ang isang elementary...  \n",
       "1  A barangay kagawad was shot dead in front of b...  \n",
       "2  GENEVA, Switzerland - Taliban restrictions on ...  \n",
       "3  The National Privacy Commission (NPC) has issu...  \n",
       "4  STOCKHOLM, Sweden - More than 600 young people...  "
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_GMA` : contians the combined GMA news data\n",
    " \n",
    "df_GMA = pd.concat([df_gma1,df_gma2], ignore_index=True)\n",
    "df_GMA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e06932-9354-4008-ab27-7dd390fa0a4b",
   "metadata": {},
   "source": [
    "#### Dataset Description\n",
    "\n",
    "\n",
    "Now, let us view the description of the Rappler data using the [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "1263c7b8-d9ab-41ad-a5f3-34b331e4f771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16006 entries, 0 to 16005\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  9785 non-null   float64\n",
      " 1   Link        16006 non-null  object \n",
      " 2   Author      16006 non-null  object \n",
      " 3   Content     16006 non-null  object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 500.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# `df_GMA` : contians the combined GMA news data\n",
    "\n",
    "df_GMA.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500489e3-b3c8-4bcb-8257-004fd2eac781",
   "metadata": {},
   "source": [
    "From this, we can see that there are **16006 articles (rows)** and **4 columns** for this dataset. Null values were present in one of the columns named `Unamed: 0` as stated from the output above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b24eada-79fe-44e5-bf2b-e41f3948f01f",
   "metadata": {},
   "source": [
    "#### Fixing the Dataset Structure\n",
    "##### **`Dropping Columns`**\n",
    "Next, similar to the processing of Rappler data, we will only be retrieving the `Content` column from the dataset which would be done through dropping the rest of the columns using the [`drop()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html?highlight=drop#pandas.DataFrame.drop). This will be the new value of the `df_GMA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "3ef908b6-23e3-417a-a644-1f04c9212568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arestado ng Laguna Police ang isang elementary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A barangay kagawad was shot dead in front of b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENEVA, Switzerland - Taliban restrictions on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The National Privacy Commission (NPC) has issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STOCKHOLM, Sweden - More than 600 young people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16001</th>\n",
       "      <td>SEOUL - North Korea said on Sunday it had test...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16002</th>\n",
       "      <td>Former US President Jimmy Carter has decided t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16003</th>\n",
       "      <td>The search for the Cessna plane which went mis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16004</th>\n",
       "      <td>The search and rescue operations for the missi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16005</th>\n",
       "      <td>A group of officials from Shanghai arrived in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16006 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Content\n",
       "0      Arestado ng Laguna Police ang isang elementary...\n",
       "1      A barangay kagawad was shot dead in front of b...\n",
       "2      GENEVA, Switzerland - Taliban restrictions on ...\n",
       "3      The National Privacy Commission (NPC) has issu...\n",
       "4      STOCKHOLM, Sweden - More than 600 young people...\n",
       "...                                                  ...\n",
       "16001  SEOUL - North Korea said on Sunday it had test...\n",
       "16002  Former US President Jimmy Carter has decided t...\n",
       "16003  The search for the Cessna plane which went mis...\n",
       "16004  The search and rescue operations for the missi...\n",
       "16005  A group of officials from Shanghai arrived in ...\n",
       "\n",
       "[16006 rows x 1 columns]"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_GMA` : contains the collected real news data from GMA News\n",
    "\n",
    "# Only retrieving the Content column of the GMA News Data\n",
    "df_GMA.drop([\"Unnamed: 0\", \"Link\", \"Author\"], axis=1, inplace=True)\n",
    "\n",
    "df_GMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cd4992-761b-4507-a3a6-cdc614a50caa",
   "metadata": {},
   "source": [
    "##### **`Adding the \"label\" Column`**\n",
    "From this, we will now concatenate the `label` column with zero values in all rows since the GMA News data contains real news data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "2a74c1d3-28a2-4dba-a0cc-98ed387c6b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arestado ng Laguna Police ang isang elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A barangay kagawad was shot dead in front of b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENEVA, Switzerland - Taliban restrictions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The National Privacy Commission (NPC) has issu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STOCKHOLM, Sweden - More than 600 young people...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16001</th>\n",
       "      <td>SEOUL - North Korea said on Sunday it had test...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16002</th>\n",
       "      <td>Former US President Jimmy Carter has decided t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16003</th>\n",
       "      <td>The search for the Cessna plane which went mis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16004</th>\n",
       "      <td>The search and rescue operations for the missi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16005</th>\n",
       "      <td>A group of officials from Shanghai arrived in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16006 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Content  label\n",
       "0      Arestado ng Laguna Police ang isang elementary...      0\n",
       "1      A barangay kagawad was shot dead in front of b...      0\n",
       "2      GENEVA, Switzerland - Taliban restrictions on ...      0\n",
       "3      The National Privacy Commission (NPC) has issu...      0\n",
       "4      STOCKHOLM, Sweden - More than 600 young people...      0\n",
       "...                                                  ...    ...\n",
       "16001  SEOUL - North Korea said on Sunday it had test...      0\n",
       "16002  Former US President Jimmy Carter has decided t...      0\n",
       "16003  The search for the Cessna plane which went mis...      0\n",
       "16004  The search and rescue operations for the missi...      0\n",
       "16005  A group of officials from Shanghai arrived in ...      0\n",
       "\n",
       "[16006 rows x 2 columns]"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_GMA` : contains the collected real news data from GMA News\n",
    "\n",
    "# Only retrieving the Content column of the GMA News Data and declaring it as a new dataframe\n",
    "df_GMA['label'] = 0\n",
    "\n",
    "df_GMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46843dd8-41fb-4c6b-9cc3-a1c749929ef9",
   "metadata": {},
   "source": [
    "##### **`Rearranging Columns`**\n",
    "Lastly, we will rearrange the columns once again where the `label` column is the first column of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "beba8c89-04c2-4b41-91e1-a0f2d7761f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Arestado ng Laguna Police ang isang elementary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A barangay kagawad was shot dead in front of b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>GENEVA, Switzerland - Taliban restrictions on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>The National Privacy Commission (NPC) has issu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>STOCKHOLM, Sweden - More than 600 young people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16001</th>\n",
       "      <td>0</td>\n",
       "      <td>SEOUL - North Korea said on Sunday it had test...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16002</th>\n",
       "      <td>0</td>\n",
       "      <td>Former US President Jimmy Carter has decided t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16003</th>\n",
       "      <td>0</td>\n",
       "      <td>The search for the Cessna plane which went mis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16004</th>\n",
       "      <td>0</td>\n",
       "      <td>The search and rescue operations for the missi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16005</th>\n",
       "      <td>0</td>\n",
       "      <td>A group of officials from Shanghai arrived in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16006 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content\n",
       "0          0  Arestado ng Laguna Police ang isang elementary...\n",
       "1          0  A barangay kagawad was shot dead in front of b...\n",
       "2          0  GENEVA, Switzerland - Taliban restrictions on ...\n",
       "3          0  The National Privacy Commission (NPC) has issu...\n",
       "4          0  STOCKHOLM, Sweden - More than 600 young people...\n",
       "...      ...                                                ...\n",
       "16001      0  SEOUL - North Korea said on Sunday it had test...\n",
       "16002      0  Former US President Jimmy Carter has decided t...\n",
       "16003      0  The search for the Cessna plane which went mis...\n",
       "16004      0  The search and rescue operations for the missi...\n",
       "16005      0  A group of officials from Shanghai arrived in ...\n",
       "\n",
       "[16006 rows x 2 columns]"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_GMA` : contains the collected real news data from GMA News\n",
    "\n",
    "# rearranging the order of columns\n",
    "df_GMA = df_GMA[['label', 'Content']]\n",
    "\n",
    "df_GMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6ce6f-e179-417b-8b8d-1e43cbb602e4",
   "metadata": {},
   "source": [
    "Now that the GMA news data has the `label` and  `Content` columns only and in are correct order, we can now recheck the updated dataset description for the GMA News data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93109bf0-7e81-46e9-a2d0-a673244c2a32",
   "metadata": {},
   "source": [
    "#### Final Dataset Description\n",
    "After fixing the dataset, we will now check its updated dataset information through [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html). \n",
    "\n",
    "This is to also check if there are any null values on the `label`. If there is a null value under the `label` column, this will be automatically filled up by a `0` value to indicate that its equivalent article content is a real news. This is possible since the news from Rappler are all real news data.\n",
    "\n",
    "However, if the null values are only found in `Content` this will be not be removed for now and will be dropped later on once the combined real and fake news data will undergo data cleaning. This is to drop all article rows with null `Content` values all in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "bf0b4c8c-3b47-4cd6-94e3-ae3fef558206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16006 entries, 0 to 16005\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    16006 non-null  int64 \n",
      " 1   Content  16006 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 250.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_GMA.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6babfeb-5282-4b5f-bbb0-ada475f7732f",
   "metadata": {},
   "source": [
    "Now that we know that there are no null values on both columns of the GMA data, let us now proceed to importing the next data, the fake news data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44467270",
   "metadata": {},
   "source": [
    "## **`Real and Fake News`** Data\n",
    "It is important to note that the fake news data to be used in the project will be from the datasets to be processed under this section. However, we will still use the real news data from these datasets.\n",
    "\n",
    "### `HuggingFace` Data\n",
    "Just like what we did in our real news data, we will also load the real and fake news dataset (**`fake news dataset.csv`**) retrieved from one of the [`HuggingFace datasets`](https://huggingface.co/datasets/fake_news_filipino) using the [`read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). We will store the imported data to `df_HuggingFace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "2bd7d6b8-1b65-4f1c-b122-ae5287c55268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ayon sa TheWrap.com, naghain ng kaso si Krupa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Kilala rin ang singer sa pagkumpas ng kanyang ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>BLANTYRE, Malawi (AP) -- Bumiyahe patungong Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Kasama sa programa ang pananalangin, bulaklak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Linisin ang Friendship Department dahil dadala...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            article\n",
       "0      0  Ayon sa TheWrap.com, naghain ng kaso si Krupa,...\n",
       "1      0  Kilala rin ang singer sa pagkumpas ng kanyang ...\n",
       "2      0  BLANTYRE, Malawi (AP) -- Bumiyahe patungong Ma...\n",
       "3      0  Kasama sa programa ang pananalangin, bulaklak ...\n",
       "4      0  Linisin ang Friendship Department dahil dadala..."
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_HuggingFace` : contains the collected real and fake news data from a HuggingFace dataset\n",
    "\n",
    "df_HuggingFace = pd.read_csv('data/fake news dataset.csv')\n",
    "df_HuggingFace.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175a3fd8-5481-40f2-b0f9-cd4c16ad5017",
   "metadata": {},
   "source": [
    "#### Dataset Description\n",
    "\n",
    "To see more about the HuggingFace real and fake news data, let us view the information of the dataset by using [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "7235e287-3847-4865-b386-da7cff56afd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3206 entries, 0 to 3205\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    3206 non-null   int64 \n",
      " 1   article  3206 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 50.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_HuggingFace.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac50b0f-f90d-4a13-9a46-c9e7e7503618",
   "metadata": {
    "tags": []
   },
   "source": [
    "From the output above, the dataset has **3206 articles** and **2 columns**. Moreover, no null values were present in the dataset as the ouput above indicates that <u>both columns have 3206 non-null values out of the 3206 rows</u>.\n",
    "\n",
    "In this case, we don't have to add or drop any columns since the only columns that the dataset has is the `label` and the `article`, representing the article content. These columns are exactly what we need later for data combination.\n",
    "\n",
    "\n",
    "#### Fixing the Dataset Structure\n",
    "Howver, seeing that the name of the column that represents the article content data is named as `article`. We will have to rename the column to `Content` to follow the dataset structure for the data combination later on. \n",
    "\n",
    "##### **`Renaming \"article\" Column`**\n",
    "Now, we will be renaming the `article` column to `Content` using the [`rename()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html?highlight=rename#pandas.DataFrame.rename), so that it would also match the column name of the real news data we processed previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "c0e1a048-f939-41c4-b9fe-b5ae34bee77d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ayon sa TheWrap.com, naghain ng kaso si Krupa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Kilala rin ang singer sa pagkumpas ng kanyang ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>BLANTYRE, Malawi (AP) -- Bumiyahe patungong Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Kasama sa programa ang pananalangin, bulaklak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Linisin ang Friendship Department dahil dadala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>1</td>\n",
       "      <td>Hindi pa nai-enjoy ni Giacomo Filibeck ang Pil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>1</td>\n",
       "      <td>Sa isang pahayag, binatikos ng Liberal Party (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>1</td>\n",
       "      <td>Panoorin nyo yung reaction video na ito ni Mr....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>1</td>\n",
       "      <td>Para sa mga magkakapatid na laging nagtatalo l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>1</td>\n",
       "      <td>Grabe ibang klase talaga si Vice Ganda kung ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3206 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            Content\n",
       "0         0  Ayon sa TheWrap.com, naghain ng kaso si Krupa,...\n",
       "1         0  Kilala rin ang singer sa pagkumpas ng kanyang ...\n",
       "2         0  BLANTYRE, Malawi (AP) -- Bumiyahe patungong Ma...\n",
       "3         0  Kasama sa programa ang pananalangin, bulaklak ...\n",
       "4         0  Linisin ang Friendship Department dahil dadala...\n",
       "...     ...                                                ...\n",
       "3201      1  Hindi pa nai-enjoy ni Giacomo Filibeck ang Pil...\n",
       "3202      1  Sa isang pahayag, binatikos ng Liberal Party (...\n",
       "3203      1  Panoorin nyo yung reaction video na ito ni Mr....\n",
       "3204      1  Para sa mga magkakapatid na laging nagtatalo l...\n",
       "3205      1  Grabe ibang klase talaga si Vice Ganda kung ma...\n",
       "\n",
       "[3206 rows x 2 columns]"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_HuggingFace` : contains the collected real and fake news data from a HuggingFace dataset\n",
    "\n",
    "# renames the 'article' column to 'Content'\n",
    "df_HuggingFace.rename(columns={'article': 'Content'}, inplace=True) #renamed column\n",
    "df_HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52fb35d-9c2c-47d9-9122-c190e6e6f382",
   "metadata": {},
   "source": [
    "Since this data already has the `label` and  `Content` columns in correct order, the updated dataset description for the HuggingFace data will be checked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ed821-7a71-403d-8b86-bd49b6e4e0b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Final Dataset Description\n",
    "After fixing the HuggingFace dataset, let us check its updated dataset information through [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html). \n",
    "\n",
    "This is to also check if there are any null values on the `label`. Unlike the GMA and Rappler Real news data, if there is a null value under the `label` column, the rows involved will be automatically dropped since both fake and real news data are present in this dataset. Filling up the null `label` values will not be possible since the news from HuggingFace data are a mix of real and fake news data. Therefore, if the `label` value of a row is null regardless of the value of its responding `Content` data, there will be no indicator if the article content is real or fake.  \n",
    "\n",
    "However, if the null values are only found in `Content` this will be not be removed for now and will be dropped later on once the combined real and fake news data will undergo data cleaning. This is to drop all article rows with null `Content` values all in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "c6cf2480-9935-4c0a-ac71-6ff9b21bd0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3206 entries, 0 to 3205\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    3206 non-null   int64 \n",
      " 1   Content  3206 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 50.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_HuggingFace.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed548a-5434-4b9b-91cd-c19e7a7c2d86",
   "metadata": {},
   "source": [
    "Now that we know that there are no null values present in any of the columns in the HuggingFace data, we will now proceed to importing another real and fake news dataset, this time, from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c4273",
   "metadata": {},
   "source": [
    "### `Kaggle` Data\n",
    "Similar to HuggingFace data, we will also load the real and fake news dataset (**`fake_or_real_news.csv`**) we retrieved from [`Kaggle`](https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification) through using the [`read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). This data will be stored to `df_Kaggle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "ffce832c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_Kaggle` : contains the collected real and fake news data from Kaggle\n",
    "\n",
    "df_Kaggle = pd.read_csv('data/fake_or_real_news.csv')\n",
    "df_Kaggle.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622ba953-df99-45b3-820a-082414a8f466",
   "metadata": {},
   "source": [
    "#### Dataset Description\n",
    "\n",
    "Getitng to know the Kaggle real and fake news data, let'ss view the dataset information through the use of [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "bb1e5959-4353-4a95-b12a-dfc7c5d0dcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6335 entries, 0 to 6334\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  6335 non-null   int64 \n",
      " 1   title       6335 non-null   object\n",
      " 2   text        6335 non-null   object\n",
      " 3   label       6335 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 198.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# `df_Kaggle` : contains the collected real and fake news data from Kaggle\n",
    "\n",
    "df_Kaggle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c3ae7b-4ccf-4f8d-8691-9b230e72c900",
   "metadata": {
    "tags": []
   },
   "source": [
    "From the output above, the dataset has **6335 articles** and **4 columns**. To add, as seen from the output above, there are no null values present in the dataset as the output indicates that <u>all columns have 6335 non-null values out of the 6335 rows</u>.\n",
    "\n",
    "#### Fixing the Dataset Structure\n",
    "Howver, seeing that the name of the column that represents the article content data is named as `text` in this dataset. We will have to rename the column to `Content` to follow the dataset structure for the data combination later on. \n",
    "\n",
    "##### **`Renaming \"text\" Column`**\n",
    "Now, let's rename the `article` column to `Content` using the [`rename()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html?highlight=rename#pandas.DataFrame.rename), so that it would also match the column name of the content news data we have processed so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "94618dc1-f7e2-417c-b8c9-e91e15fce23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>Content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>4490</td>\n",
       "      <td>State Department says it can't find emails fro...</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>8062</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>8622</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligarc...</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>4021</td>\n",
       "      <td>In Ethiopia, Obama seeks progress on peace, se...</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>4330</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              title  \\\n",
       "0           8476                       You Can Smell Hillary’s Fear   \n",
       "1          10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2           3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3          10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4            875   The Battle of New York: Why This Primary Matters   \n",
       "...          ...                                                ...   \n",
       "6330        4490  State Department says it can't find emails fro...   \n",
       "6331        8062  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332        8622  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333        4021  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334        4330  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                Content label  \n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4     It's primary day in New York and front-runners...  REAL  \n",
       "...                                                 ...   ...  \n",
       "6330  The State Department told the Republican Natio...  REAL  \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
       "\n",
       "[6335 rows x 4 columns]"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_Kaggle` : contains the collected real and fake news data from Kaggle\n",
    "\n",
    "# renames the 'text' column to 'Content'\n",
    "df_Kaggle.rename(columns={'text': 'Content'}, inplace=True)\n",
    "df_Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69698d69-aa22-4437-8808-cc137fc8778a",
   "metadata": {},
   "source": [
    "##### **`Dropping and Rearranging Columns`**\n",
    "Similar to the datasets we have processed so far, we will only be retrieving the `Content` and `label` columns from the dataset. This will be the new value of the `df_Kaggle`. \n",
    "\n",
    "To drop other unnecessary columns, <u>another way to drop columns is to **only specify the columns we need** in any order</u>. With this, let us also specify the columns in the order that we want ([`label`, `Content`])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "358dbeff-76a3-45bd-84b8-41f18109b67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REAL</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REAL</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>REAL</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>FAKE</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>REAL</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>REAL</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            Content\n",
       "0     FAKE  Daniel Greenfield, a Shillman Journalism Fello...\n",
       "1     FAKE  Google Pinterest Digg Linkedin Reddit Stumbleu...\n",
       "2     REAL  U.S. Secretary of State John F. Kerry said Mon...\n",
       "3     FAKE  — Kaydee King (@KaydeeKing) November 9, 2016 T...\n",
       "4     REAL  It's primary day in New York and front-runners...\n",
       "...    ...                                                ...\n",
       "6330  REAL  The State Department told the Republican Natio...\n",
       "6331  FAKE  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "6332  FAKE   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "6333  REAL  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "6334  REAL  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[6335 rows x 2 columns]"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_Kaggle` : contains the collected real and fake news data from Kaggle\n",
    "\n",
    "# Only retrieving the label and Content Column of the Kaggle Data \n",
    "# while specifying that the label is the first column\n",
    "df_Kaggle = df_Kaggle[['label', 'Content']]\n",
    "\n",
    "df_Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884afd9-94ba-4db5-b18d-8ea325f8a39c",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **`Checking the \"label\" values`**\n",
    "As seen from the output above the values under the `label` columns are not limited to `0` or `1`. Let us check the other unique values under the `label` column through using [`unique()`](https://pandas.pydata.org/docs/reference/api/pandas.unique.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "56a27595-de37-4341-ae4d-8c7aa49d4a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FAKE', 'REAL'], dtype=object)"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_Kaggle` : contains the collected real and fake news data from Kaggle\n",
    "\n",
    "df_Kaggle['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94d0a11-154e-466e-ba61-7569007c44ed",
   "metadata": {},
   "source": [
    "From the output above, the values present in the `label` column are only \"FAKE\" and \"REAL\". This case is diffrent from the `label` columns from other datasets we have processed so far where their `label` values are *\"0\" to indicate real news* and *\"1\" to indicate fake news*. \n",
    "\n",
    "##### **`Replacing \"label\" values`**\n",
    "The **'label'** column of the Kaggle data doesn't have the numerical value. With that, we will have to **replace these values from <u>\"FAKE\" and \"REAL\"</u> to <u>\"1\" and \"0\"</u>**, respectively, using the [`replace()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html?highlight=replace#pandas.DataFrame.replace)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "cd76d485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hy/wg_n_hk95j3_bhf9fkykc7d40000gn/T/ipykernel_1717/469766645.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Kaggle['label'] = df_Kaggle['label'].replace({'REAL': 0, 'FAKE': 1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6332</th>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6335 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            Content\n",
       "0         1  Daniel Greenfield, a Shillman Journalism Fello...\n",
       "1         1  Google Pinterest Digg Linkedin Reddit Stumbleu...\n",
       "2         0  U.S. Secretary of State John F. Kerry said Mon...\n",
       "3         1  — Kaydee King (@KaydeeKing) November 9, 2016 T...\n",
       "4         0  It's primary day in New York and front-runners...\n",
       "...     ...                                                ...\n",
       "6330      0  The State Department told the Republican Natio...\n",
       "6331      1  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "6332      1   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "6333      0  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "6334      0  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[6335 rows x 2 columns]"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_Kaggle` : contains the collected real and fake news data from Kaggle\n",
    "\n",
    "# assigning new values (raplacing the existing values 'REAL' and 'FAKE' with 0 and 1, respectively in the 'label' column)\n",
    "df_Kaggle['label'] = df_Kaggle['label'].replace({'REAL': 0, 'FAKE': 1})\n",
    "df_Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36007ebb-18e7-4a87-9177-965061c5d704",
   "metadata": {},
   "source": [
    "Since the Kaggle dataset already has the `label` and  `Content` columns in correct order, we will now check its updated dataset information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72449fdf-a865-449c-8a0f-171238eccf59",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Final Dataset Description\n",
    "Now that the Kaggle dataset is fixed, we will check use the [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html) to check its updated dataset information. \n",
    "\n",
    "This is to also check if there are any null values on the `label`. This case is <u>similar to the HuggingFace dataset</u> which is <u>different from the GMA News and Rappler</u> real news data. In this case, if there is a null value under the `label` column, the rows involved will be automatically dropped since both fake and real news data are present in this dataset. Filling up the null `label` values will not be possible since the news from Kaggle data are a mix of real and fake news data. Therefore, if the `label` value of a row is null regardless of the value of its responding `Content` data, there will be no indicator if the article content is real or fake.  \n",
    "\n",
    "However, if the null values are only found in `Content` this will be not be removed for now and will be dropped later on once the combined real and fake news data will undergo data cleaning. This is to drop all article rows with null `Content` values all in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "1a58e190-ad31-4459-90ae-1daa3cdcad16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6335 entries, 0 to 6334\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    6335 non-null   int64 \n",
      " 1   Content  6335 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 99.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_Kaggle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a744544f-19ef-4e9d-abcf-9478af8ec48d",
   "metadata": {},
   "source": [
    "As seen from the output above, there are no null values present in any of the columns in the Kaggle data. Also, since this is the last dataset to be processed, we can now proceed to combining all the processed datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c57862",
   "metadata": {},
   "source": [
    "## Combining Real and Fake News Datasets\n",
    "In this last part of the pre-procesing, all processed datasets will be merged together using [`concat()`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html?highlight=concat#pandas.concat) into a single DataFrame called `df_News`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "10fe57ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            Content\n",
       "0      0  MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1      0  MANILA, Philippines – The results of the lates...\n",
       "2      0  Tom Brady was the ultimate winner on the field...\n",
       "3      0  It’s one thing to know what makes people happy...\n",
       "4      0  Justin Bieber is the latest artist in a growin..."
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `df_Rappler` : contains the collected and processed  real news data from Rappler\n",
    "# `df_GMA` : contians the collected and processed  GMA news data\n",
    "# `df_HuggingFace` : contains the collected and processed  real and fake news data from a HuggingFace dataset\n",
    "# `df_Kaggle` : contains the collected and processed  real and fake news data from Kaggle\n",
    "\n",
    "# `df_News` : contains all of the collected and processed real and fake news data\n",
    "\n",
    "df_News = pd.concat([df_Rappler, df_GMA, df_HuggingFace, df_Kaggle], ignore_index=True)\n",
    "df_News.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ce2fa-9d55-4792-9b63-817cef3883c6",
   "metadata": {},
   "source": [
    "#### Initial Dataset Description of the Combined News Data\n",
    "Now that there is a combined news dataset, which contains all of the datasets we have collected and recently processed, we will now check the information of the combined dataset with the help of the [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html). \n",
    "\n",
    "This case is <u>similar to the real and fake news datasets</u> we have processed since all of the data we collected are now combined in one dataset. If there is a null value under the `label` column, the rows involved will be automatically dropped since both fake and real news data are present in this dataset. Filling up the null `label` values will not be possible since the news from Kaggle data are a mix of real and fake news data. Therefore, if the `label` value of a row is null regardless of the value of its responding `Content` data, there will be no indicator if the article content is real or fake.  \n",
    "\n",
    "However, if the null values are only found in `Content` this will be not be removed for now and will be dropped later on once the combined real and fake news data will undergo data cleaning. \n",
    "\n",
    "For now, we will use the [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html) to view the current dataset description of the combined news dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "f2473411-61e0-4940-babb-f0b94e717e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26749 entries, 0 to 26748\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    26749 non-null  int64 \n",
      " 1   Content  26748 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 418.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_News.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d2ec3f-2ce2-469a-a1dc-b31c1462f112",
   "metadata": {},
   "source": [
    "There are currently **26,749 rows** for the combined news data before the data cleaning. To add, a null value is present under the `Content` column.\n",
    "\n",
    "Since this is the last part of the data preprocessing, we can now proceed to data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d50d2-e0b7-4afb-8849-9e0124e0c888",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acadf1c",
   "metadata": {},
   "source": [
    "## Removing Unwanted Characters or Formatting\n",
    "Data often contains unwanted characters or formatting that can make it challenging to work with. So, to remove specific characters from a text, we defined a function that would **return a string without \\n, \\t, \\r, and \\r\\n\\r characters**, as well as **backlash characters from the text**. After that, the function would be applied to the `Content` column of the combined news data (`df_News`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "f6e44555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning function to remove newline and tab formatting from the text\n",
    "def remove_newline_tab(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ').replace('\\r\\n\\r', ' ')\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Cleaning function to remove backslash formatting from a text    \n",
    "def remove_backslashes(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.replace('\\\\', '')\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db8947f",
   "metadata": {},
   "source": [
    "After that, both `remove_newline_tab` and `remove_backslashes` functions would be applied to the `Content` column of the combined news data `df_News`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "9d5561f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MANILA, Philippines – Finally! Best-selling Japanese author Haruki Murakami is will be releasing a new novel – his first in six years – on April 13, 2023. Publisher Shinchosa made the announcement on Wednesday, February 1. Although the title and plot have not been released yet, Shinchosa said that the book will be initially published in Japanese, with translations following later on. There is still no specific date on when the translated versions will be released. The novel will be “1,200 Japanese manuscript pages long,” Shinchosa said, and will cost 2,970 yen. An order link to the physical and e-book copy is already up on the website. This will be Murakami’s latest novel since the release of Killing Commendatore in 2017. Award-winning writer Murakami, 74, is best known domestically and internationally for his magical realist short stories and novels, such as Norwegian Wood (1987), Kafka on the Shore (2002), 1Q84 (2009), and Wind-Up Bird Chronicle (1994), among many others. – Rappler.com\n"
     ]
    }
   ],
   "source": [
    "# Applies both remove_newline_tab and remove_backslashes functions to each row oft the 'Content' column\n",
    "df_News['Content'] = df_News['Content'].apply(remove_newline_tab)\n",
    "df_News['Content'] = df_News['Content'].apply(remove_backslashes)\n",
    "\n",
    "# Shows a sample output of a row after applying both functions\n",
    "print(df_News.loc[0, 'Content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d537c330-81c7-49ad-ba96-45814a8ab5cd",
   "metadata": {},
   "source": [
    "## Removing Web Links or URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8712abd9",
   "metadata": {},
   "source": [
    "We also define a function that **remove any web links or URLs** that might be present in the text of the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "id": "3b41f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning function to remove links from text\n",
    "def remove_links(text):\n",
    "    # Regular expression pattern to match URLs\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    \n",
    "    # Replace URLs with an empty string\n",
    "    return re.sub(url_pattern, '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e678c2c",
   "metadata": {},
   "source": [
    "Then, **to remove web links or urls** from the `Content` data, we apply the `remove_links` function to the `Content` column of the combined news data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "70104ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26744</th>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26745</th>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26746</th>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26747</th>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26748</th>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26749 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content\n",
       "0          0  MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1          0  MANILA, Philippines – The results of the lates...\n",
       "2          0  Tom Brady was the ultimate winner on the field...\n",
       "3          0  It’s one thing to know what makes people happy...\n",
       "4          0  Justin Bieber is the latest artist in a growin...\n",
       "...      ...                                                ...\n",
       "26744      0  The State Department told the Republican Natio...\n",
       "26745      1  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "26746      1   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "26747      0  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "26748      0  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[26749 rows x 2 columns]"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply web link or URL cleaning to the 'Content' column \n",
    "df_News['Content'] = df_News['Content'].astype(str).apply(remove_links)\n",
    "df_News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a13d6e-f92a-429c-95b7-66e6dd0974d2",
   "metadata": {},
   "source": [
    "## Removing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b0e32",
   "metadata": {},
   "source": [
    "Finally, we will also define a function that will be **removing any images** that might be embedded in the text of the `Content` column of the combined news data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "16d5419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning function to remove embedded images from article content text\n",
    "def remove_images(text):\n",
    "    # Define a regular expression pattern to match base64-encoded strings (images)\n",
    "    base64_pattern = r\"data:image\\/(png|jpg|jpeg|gif|bmp);base64,[A-Za-z0-9+/=]+\"\n",
    "\n",
    "    # Use the re.sub() function to replace the base64-encoded strings with an empty string\n",
    "    cleaned_text = re.sub(base64_pattern, '', text)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69c18fd",
   "metadata": {},
   "source": [
    "Then, we apply the `remove_images` function to the `Content` column to remove the embedded images from its text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "7d5402f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26744</th>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26745</th>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26746</th>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26747</th>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26748</th>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26749 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content\n",
       "0          0  MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1          0  MANILA, Philippines – The results of the lates...\n",
       "2          0  Tom Brady was the ultimate winner on the field...\n",
       "3          0  It’s one thing to know what makes people happy...\n",
       "4          0  Justin Bieber is the latest artist in a growin...\n",
       "...      ...                                                ...\n",
       "26744      0  The State Department told the Republican Natio...\n",
       "26745      1  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "26746      1   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "26747      0  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "26748      0  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[26749 rows x 2 columns]"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_News['Content'] = df_News['Content'].astype(str).apply(remove_images)\n",
    "df_News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3338e754-921d-4b6b-9b15-1a8e652c4042",
   "metadata": {},
   "source": [
    "Since we are now done with cleaning each `Content` data, we will now <u>check if there are rows with **only white space left**, **null value**, or **duplicated** values</u> because of changes brought by the cleaning of each article content under the `Content` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa08eb-4adf-4592-b003-e44ae3ccec44",
   "metadata": {},
   "source": [
    "## Dropping Rows with white spaces only\n",
    "\n",
    "This is to check the rows under the `Content` column of the news data (`df_News`) if there values with white space only. If the `Content` value of a row is found to only have white space, we will drop these rows by only retrieving those that has actual content or non white space data from the original copy of the combined data. Then, we will update the combined news data by storing the data we retrieved to `df_News`, which represents the original combined data.\n",
    "\n",
    "Now, let us check if there are any rows with white space `Content` value. To do this, we will be using the [`isspace()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html#:~:text=Check%20whether%20all%20characters%20in,element%20of%20the%20Series%2FIndex.) and the [`value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) to count those rows with white space values and those that are not in white space value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "daba3833-ce70-4d1b-8099-ba43750465a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    26713\n",
       "True        36\n",
       "Name: Content, dtype: int64"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_News_space_count = pd.Series(df_News['Content']).str.isspace().value_counts()\n",
    "df_News_space_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042555e0-e1bc-40d0-ba3c-f7db81d1e014",
   "metadata": {},
   "source": [
    "From output above, it is evident that **36 rows contain a white space value** under its `Content` value. From this, we will be dropping these column and update the original copy of the combined news data through only storing those with actual content. \n",
    "\n",
    "The rows with <u>actual content or non white space values</u> are those that resulted to **\"False\" from using the [`isspace()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.isspace.html#:~:text=Check%20whether%20all%20characters%20in,element%20of%20the%20Series%2FIndex.)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "2e362364-527e-4112-a63b-7328c2d0ae45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26744</th>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26745</th>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26746</th>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26747</th>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26748</th>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26713 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content\n",
       "0          0  MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1          0  MANILA, Philippines – The results of the lates...\n",
       "2          0  Tom Brady was the ultimate winner on the field...\n",
       "3          0  It’s one thing to know what makes people happy...\n",
       "4          0  Justin Bieber is the latest artist in a growin...\n",
       "...      ...                                                ...\n",
       "26744      0  The State Department told the Republican Natio...\n",
       "26745      1  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "26746      1   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "26747      0  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "26748      0  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[26713 rows x 2 columns]"
      ]
     },
     "execution_count": 789,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_News = df_News[pd.Series(df_News['Content']).str.isspace() == False]\n",
    "df_News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eabe46-be3d-4507-84f2-1d28e996c32c",
   "metadata": {},
   "source": [
    "As seen from the information above, we can confirm that there were whitespace values under the `Content` column since there are 26,713 rows left out of 26749 rows. \n",
    "\n",
    "Since we dropped some rows, we will also use the [`reset_index()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) to update the index of the updated dataframe. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "b62c3eb9-2d3b-4a75-b7c1-f399d2ecbf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26708</th>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26709</th>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26710</th>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26711</th>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26712</th>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26713 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content\n",
       "0          0  MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1          0  MANILA, Philippines – The results of the lates...\n",
       "2          0  Tom Brady was the ultimate winner on the field...\n",
       "3          0  It’s one thing to know what makes people happy...\n",
       "4          0  Justin Bieber is the latest artist in a growin...\n",
       "...      ...                                                ...\n",
       "26708      0  The State Department told the Republican Natio...\n",
       "26709      1  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "26710      1   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "26711      0  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "26712      0  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[26713 rows x 2 columns]"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updating the index of the updated dataframe\n",
    "df_News = df_News.reset_index(drop=True)\n",
    "\n",
    "df_News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc39c0-d2ec-4189-a2d7-85937337212c",
   "metadata": {},
   "source": [
    "Then, after dropping the white space rows and resetting the index of the updated data, let us view the dataset information once again to confirm the updated non-null counts per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "ef164cf8-cb8e-4aa7-b540-06255b6de08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26713 entries, 0 to 26712\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    26713 non-null  int64 \n",
      " 1   Content  26713 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 417.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_News.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca7f9c0-cb81-4d32-a838-12a66314a6eb",
   "metadata": {},
   "source": [
    "As seen from the output above, the combined news data (`df_News`) now have a total of **26,713 rows** and **2 columns**, which are the `label` and the `Content` columns. To add, the non-null count for both columns are equal to the latest total number of rows of the dataset. This means that, at this point, there are no more rows with null values in any of the columns among the rows of the combined news data (`df_News`). This may be due to dropping the white space only values under the `Content` column. \n",
    "\n",
    "However, to ensure that there are no null values left, let us proceed to <u>specifically checking for null values</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653f5593-7968-4423-a346-9c855ac7dd02",
   "metadata": {},
   "source": [
    "## Checking for Null Values\n",
    "\n",
    "This section is mainly for checking the `Content` column of the news data (`df_News`). A specific row will be dropped using [`dropna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html?highlight=dropna#pandas.DataFrame.dropna) if its 'Content' is found to be null. This is because the 'Content' column is a crucial aspect of the dataset which contains the actual text or content of the news articles and essential for any text-based analysis, such as sentiment analysis, or natural language processing (NLP). This is also to maintain data integrity and ensure accurate analysis, it is best to drop the row with the null value in the 'Content' column. \n",
    "\n",
    "Despite being checked on the preprocessing part of the project, the `label` column will still be checked if there are null values. To ensure that all news data have an indicator whether the article content is fake or real.\n",
    "\n",
    "In this way, the rest of the dataset remains intact and retains its value for further exploratory data analysis and text-based tasks. The removal of the row with the null value allows us to work with complete and reliable data, which is crucial for obtaining meaningful insights from the dataset.\n",
    "\n",
    "First, let's check the information of the combined news data (`df_News`) from the preprocessing by using [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "id": "26c6fd4c-1030-4b0c-886d-5a5c7d1dfd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26713 entries, 0 to 26712\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    26713 non-null  int64 \n",
      " 1   Content  26713 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 417.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_News.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a058c-6933-4083-bf7c-41c1f9671550",
   "metadata": {},
   "source": [
    "As seen from the information above, we can confirm that there are no null values under  both columns since the output indicated that the non-null count for both columns are equal to the total number of rows of the dataset. \n",
    "\n",
    "To ensure that there will be no null values left, after the cleaning let us use the [`dropna()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) to drop values with null values under the `Content` column. Since it is still possible that rows may be dropped, we will also use the [`reset_index()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) after to update the index of the updated dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "id": "36cd8593-c5c5-49c4-85ae-ba28fd69eb31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26708</th>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26709</th>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26710</th>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26711</th>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26712</th>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26713 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content\n",
       "0          0  MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1          0  MANILA, Philippines – The results of the lates...\n",
       "2          0  Tom Brady was the ultimate winner on the field...\n",
       "3          0  It’s one thing to know what makes people happy...\n",
       "4          0  Justin Bieber is the latest artist in a growin...\n",
       "...      ...                                                ...\n",
       "26708      0  The State Department told the Republican Natio...\n",
       "26709      1  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "26710      1   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "26711      0  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "26712      0  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[26713 rows x 2 columns]"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the rows with null values under the `Content` column\n",
    "df_News.dropna(subset=['Content'], inplace=True)\n",
    "\n",
    "# Updating the index of the updated dataframe\n",
    "df_News = df_News.reset_index(drop=True)\n",
    "\n",
    "df_News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d8d4e-340a-47e9-9202-9e4645b81bdc",
   "metadata": {},
   "source": [
    "Then, after dropping the null row and resetting the index ofthe updated data, let us view the dataset information once again to confirm the updated non-null counts per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "3459b539-8f40-4891-87e4-693db12fe087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26713 entries, 0 to 26712\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    26713 non-null  int64 \n",
      " 1   Content  26713 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 417.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_News.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656d42dc-43a7-4f2c-b5bb-542ef6b59e1f",
   "metadata": {},
   "source": [
    "As seen from the output above, the combined news data (`df_News`) still have a total of **26,713 rows** and **2 columns**, which are the `label` and the `Content` columns. The non-null count for both columns are equal to the total number of rows of the dataset. This means that there are no more rows with null values in any of the columns among the rows of the combined news data (`df_News`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981a9958-f889-4550-b8cd-a8404647cf86",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dropping Duplicated Rows\n",
    "To ensure the quality and accuracy of the data in the analysis, we will also be  removing duplicated rows in the combined dataset using [`drop_duplicates()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html?highlight=drop_duplicates#pandas.DataFrame.drop_duplicates). This so that potential biases or issues can be avoided which may  arise when dealing with duplicated information.\n",
    "\n",
    "As seen from the result above, the combined news data has **26,713 rows** and **2 columns**. Now, before dropping the duplicates right away, let us first check the number of duplicated rows with the help of the [`duplicated()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html). This is to know the total number of rows to expect after dropping the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "086553d9-08da-4752-b175-f8e7d5b5ae9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>Art by Andoy Edoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>0</td>\n",
       "      <td>Arestado sa entrapment operation sa Masbate an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>0</td>\n",
       "      <td>Nauwi sa krimen ang inuman ng dalawang lalaki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0</td>\n",
       "      <td>Nauwi sa krimen ang inuman ng dalawang lalaki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>0</td>\n",
       "      <td>Voter registration for Barangay and Sanggunian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26579</th>\n",
       "      <td>0</td>\n",
       "      <td>During the campaign, Trump had threatened to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26606</th>\n",
       "      <td>1</td>\n",
       "      <td>Email  ISIS barbarians used an industrial doug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26612</th>\n",
       "      <td>1</td>\n",
       "      <td>Email  North Korea’s Foreign Ministry slammed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26629</th>\n",
       "      <td>0</td>\n",
       "      <td>A verdict in 2017 could have sweeping conseque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26649</th>\n",
       "      <td>0</td>\n",
       "      <td>Killing Obama administration rules, dismantlin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3579 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content\n",
       "568        0                                Art by Andoy Edoria\n",
       "1484       0  Arestado sa entrapment operation sa Masbate an...\n",
       "1498       0  Nauwi sa krimen ang inuman ng dalawang lalaki ...\n",
       "1499       0  Nauwi sa krimen ang inuman ng dalawang lalaki ...\n",
       "1536       0  Voter registration for Barangay and Sanggunian...\n",
       "...      ...                                                ...\n",
       "26579      0  During the campaign, Trump had threatened to i...\n",
       "26606      1  Email  ISIS barbarians used an industrial doug...\n",
       "26612      1  Email  North Korea’s Foreign Ministry slammed ...\n",
       "26629      0  A verdict in 2017 could have sweeping conseque...\n",
       "26649      0  Killing Obama administration rules, dismantlin...\n",
       "\n",
       "[3579 rows x 2 columns]"
      ]
     },
     "execution_count": 795,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_News[df_News.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e431f-a8b1-47fe-ab9e-c775c150161c",
   "metadata": {},
   "source": [
    "Since the result above shows that there are **3,579 duplicated rows**, we subtract this from the current total number of rows (**26,713 rows**) of the combined news data (`df_News`). From this, we <u>expect the updated combined news data to have 23,134 rows</u> after the dropping of duplicated rows.\n",
    "\n",
    "Now, let us **drop the duplicated rows** and <u>see the updated shape</u> of the combined news data after the dropping of duplicates. Since some rows will be dropped, we will also use the [`reset_index()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) to update the index of the updated dataframe. \n",
    "\n",
    "Then, we will use the [`info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html) once again to check the dataset information, especially the total number of rows and the non-null counts per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "id": "e8e16198-c633-4e56-a95d-7be89b465200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23129</th>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23130</th>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23131</th>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23132</th>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23133</th>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23134 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content\n",
       "0          0  MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1          0  MANILA, Philippines – The results of the lates...\n",
       "2          0  Tom Brady was the ultimate winner on the field...\n",
       "3          0  It’s one thing to know what makes people happy...\n",
       "4          0  Justin Bieber is the latest artist in a growin...\n",
       "...      ...                                                ...\n",
       "23129      0  The State Department told the Republican Natio...\n",
       "23130      1  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "23131      1   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "23132      0  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "23133      0  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[23134 rows x 2 columns]"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_News = df_News.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df_News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "id": "da630f94-0489-4a17-9347-7ec594f865ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23134 entries, 0 to 23133\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    23134 non-null  int64 \n",
      " 1   Content  23134 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 361.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_News.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c5af25-32e7-46ff-aa44-0167137f6dcc",
   "metadata": {},
   "source": [
    "From the information presented above, the dataset contains **23,134 news articles** and **all rows per column are non-null** values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca56f4-411e-4d49-9216-eb8ea25c0836",
   "metadata": {},
   "source": [
    "Since this is the last part of the data cleaning process, we will now <u>sort the combined news dataset based on its **language**, and based on its **article type**</u>, if it is real or fake news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e2d3b2-c5a6-4275-a543-3d297329bf19",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Separating English and Filipino Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd8a08e",
   "metadata": {},
   "source": [
    "The combined news data contains articles **both in the English language and Filipino language**. \n",
    "\n",
    "With that, we sort these articles into two datasets: (1) `English articles` and (2) `Filipino articles`. \n",
    "\n",
    "To proceed, we use the **Natural Language Toolkit library** for this by importing words from [`nltk.corpus`](https://www.nltk.org/howto/corpus.html?highlight=set+words) that provides a collection of English words which can effeciently check if a particular word belongs to the English language or not. \n",
    "\n",
    "With this, let us <u>**retrieve the english words or vocabulary from the NLTK corpus**</u> to be used in **sorting** the combined news articles by its language text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "id": "0b349a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the English vocabulary from the NLTK corpus imported from the first part of the project\n",
    "english_words = set(words.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be77f2",
   "metadata": {},
   "source": [
    "Next, we formulated a function called `detect_language` that identifies the language of a given text. \n",
    "\n",
    "In this function, the text will be tokenized into individual words, converts them to lowercase, and then calculates the count of English and Filipino words in the text. If the <u>text contains **too few words** or is **empty**</u>, it returns **\"Unknown\"** as there is insufficient information to determine the language. Otherwise, it <u>compares the counts of English and Filipino words</u> and <u>concludes the language to be either **English or Filipino** based on **which count is higher**</u>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "id": "3f577b27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to detect the language of a text\n",
    "def detect_language(text):\n",
    "    words = wordpunct_tokenize(text.lower())\n",
    "    if len(words) == 0:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Calculate the count of English words in the text\n",
    "    english_word_count = sum(1 for word in words if word in english_words)\n",
    "    \n",
    "    # Calculate the count of Filipino words in the text\n",
    "    filipino_word_count = sum(1 for word in words if word not in english_words)\n",
    "    \n",
    "    # Check if the text contains enough words to determine the language\n",
    "    if len(words) < 5:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Check if the text has more English words than Filipino words\n",
    "    if english_word_count > filipino_word_count:\n",
    "        return 'English'  # Language is English\n",
    "    else:\n",
    "        return 'Filipino'  # Language is Filipino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5172a-599a-4f33-b845-c14f6cb0d710",
   "metadata": {},
   "source": [
    "Since we will only be needing the `language` column only for sorting the combined news data by its language text, we will not update the original copy of the combined news data (`df_News`). Instead, using the [`copy()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html), we will make a copy of the combined news data to use only for this part. In this case, we will store the copy of the combined news data to `df_News_Language`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "id": "a95f2f8b-e904-4cdb-85a6-4c1e6db939ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23129</th>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23130</th>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23131</th>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23132</th>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23133</th>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23134 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content\n",
       "0          0  MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1          0  MANILA, Philippines – The results of the lates...\n",
       "2          0  Tom Brady was the ultimate winner on the field...\n",
       "3          0  It’s one thing to know what makes people happy...\n",
       "4          0  Justin Bieber is the latest artist in a growin...\n",
       "...      ...                                                ...\n",
       "23129      0  The State Department told the Republican Natio...\n",
       "23130      1  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "23131      1   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "23132      0  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "23133      0  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[23134 rows x 2 columns]"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_News_Language = df_News.copy()\n",
    "df_News_Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cdcbec",
   "metadata": {},
   "source": [
    "Now, the function will be applied to the `Content` column of the combined news data copy (`df_News_Language`). This will create a new column called `language` to the data copy which indicates the detected language (either \"*English*,\" \"*Filipino*,\" or \"*Unknown*\") for each corresponding text in the `Content` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "74e592aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23129</th>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23130</th>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23131</th>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23132</th>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23133</th>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23134 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content language\n",
       "0          0  MANILA, Philippines – Finally! Best-selling Ja...  English\n",
       "1          0  MANILA, Philippines – The results of the lates...  English\n",
       "2          0  Tom Brady was the ultimate winner on the field...  English\n",
       "3          0  It’s one thing to know what makes people happy...  English\n",
       "4          0  Justin Bieber is the latest artist in a growin...  English\n",
       "...      ...                                                ...      ...\n",
       "23129      0  The State Department told the Republican Natio...  English\n",
       "23130      1  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  English\n",
       "23131      1   Anti-Trump Protesters Are Tools of the Oligar...  English\n",
       "23132      0  ADDIS ABABA, Ethiopia —President Obama convene...  English\n",
       "23133      0  Jeb Bush Is Suddenly Attacking Trump. Here's W...  English\n",
       "\n",
       "[23134 rows x 3 columns]"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying the detect_language function to 'Content' column\n",
    "df_News_Language['language'] = df_News_Language['Content'].apply(detect_language)\n",
    "df_News_Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e64f5c",
   "metadata": {},
   "source": [
    "After detecting the language of the text in the `Content` column, we will be creating two DataFrames wherein the data will be separated based on the language as indicated in the `language` column. Doing this can be useful **to analyze and understand these two set of news articles separately, by language**.\n",
    "\n",
    "Before separating the data by language, let us check the **tally per language detected** among the article content data. This is possible with the help of the [`value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "88ac10b1-86d2-48b6-808f-b6ac0a949d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English     17526\n",
       "Filipino     5603\n",
       "Unknown         5\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_News_Language['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805e8e23-76f6-4987-b198-643312f2351c",
   "metadata": {},
   "source": [
    "And as it turned out from theoutput above, the **English articles has 17,526 rows**, while the **Filipino articles only has 5,603 rows**. Meanwhile, **5 article data were identified as \"Unknown\"** under the `language` column. This means that there were <u>5 rows that contain too few words or is empty</u> making it insufficient information to detect the language in those rows. \n",
    "\n",
    "## Examining Article Data under 'Unknown' language \n",
    "Let us examine the rows with \"**Unknown**\" language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "id": "96681165-c989-4cc4-bff3-edec3812f90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0</td>\n",
       "      <td>Art by Andoy Edoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20468</th>\n",
       "      <td>1</td>\n",
       "      <td>Adrian Bamforth   Adrian Bamforth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20510</th>\n",
       "      <td>1</td>\n",
       "      <td>Guest   Guest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20862</th>\n",
       "      <td>1</td>\n",
       "      <td>RECENT POSTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                Content\n",
       "293        0                    Art by Andoy Edoria\n",
       "935        0                                    nan\n",
       "20468      1    Adrian Bamforth   Adrian Bamforth  \n",
       "20510      1                        Guest   Guest  \n",
       "20862      1                          RECENT POSTS "
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_News[df_News_Language['language'] == 'Unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b714ba41-e331-4b75-b03a-eca9dca4c60d",
   "metadata": {},
   "source": [
    "From this, we can use that there are **repeating words**, and **at most 4 words length** among the article content data under the **Unknown** language. \n",
    "\n",
    "Since this <u>does not make sense as a news article</u>, we can **drop these rows** from the combined news data by excluding these rows and update the original copy of the combined news data. \n",
    "\n",
    "Since some rows will be dropped, we will also use the [`reset_index()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) to update the index of the updated dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "id": "865da0f4-fd14-49d4-8ea0-fa0fdaead2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23124</th>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23125</th>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23126</th>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23127</th>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23128</th>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content\n",
       "0          0  MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1          0  MANILA, Philippines – The results of the lates...\n",
       "2          0  Tom Brady was the ultimate winner on the field...\n",
       "3          0  It’s one thing to know what makes people happy...\n",
       "4          0  Justin Bieber is the latest artist in a growin...\n",
       "...      ...                                                ...\n",
       "23124      0  The State Department told the Republican Natio...\n",
       "23125      1  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "23126      1   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "23127      0  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "23128      0  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[23129 rows x 2 columns]"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNews = df_News[df_News_Language['language'] != 'Unknown'].reset_index(drop=True)\n",
    "dfNews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4afa6-474d-459d-90be-690627847c2b",
   "metadata": {},
   "source": [
    "Now, there are currently **23,129 rows** for the combined news data. Let us now proceed to separating the article data by its identified language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad0b21",
   "metadata": {},
   "source": [
    "## `English` Article Data\n",
    "To do this, a dataframe called `df_english_news` will be created as the container of the English articles. \n",
    "\n",
    "In this section, we will **collect all the news articles written in English from the original copy of the combined news data (`df_News`) and put them in the new DataFrame `df_english_news`**. To know which of the rows from the original combined data will be included, we will use the combined data copy that has the `language` column (`df_News_Language`) to navigate the rows to be included. This specific dataframe would be useful in analyzing the English real and fake news only. \n",
    "\n",
    "We will collect English news articles from the original copy of the combined news data (`df_News`) since only want the `label` and `Content` column. To add, the `language` for all rows would have \"English\" as their value which makes the `language` column irrelevant for this case. \n",
    "\n",
    "This procedure will also be done in Filipino articles but not in articles with \"Unknown\" `language` value.\n",
    "\n",
    "Since we are specifying only English article data, we will use the [`reset_index()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) to update the index of the updated dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "id": "1948a9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17521</th>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17522</th>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17523</th>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17524</th>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17525</th>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17526 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content\n",
       "0          0  MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1          0  MANILA, Philippines – The results of the lates...\n",
       "2          0  Tom Brady was the ultimate winner on the field...\n",
       "3          0  It’s one thing to know what makes people happy...\n",
       "4          0  Justin Bieber is the latest artist in a growin...\n",
       "...      ...                                                ...\n",
       "17521      0  The State Department told the Republican Natio...\n",
       "17522      1  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "17523      1   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "17524      0  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "17525      0  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[17526 rows x 2 columns]"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english_news = df_News[df_News_Language['language'] == 'English'].reset_index(drop=True)\n",
    "df_english_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d9a19a-9404-4a0c-87df-cdf2c0312773",
   "metadata": {},
   "source": [
    "## `Filipino` Article Data\n",
    "To do this, a dataframe called `df_filipino_news` will be created as the container of the Filipino articles. \n",
    "\n",
    "In this section, we will **collect all the news articles written in Filipino from the original copy of the combined news data (`df_News`) and put them in the new DataFrame `df_Filipino_news`**. To know which of the rows from the original combined data will be included, we will use the combined data copy that has the `language` column (`df_News_Language`) to navigate the rows to be included. This specific dataframe would be useful in analyzing the Filipino real and fake news only. \n",
    "\n",
    "We will collect Filipino news articles from the original copy of the combined news data (`df_News`) since only want the `label` and `Content` column. To add, the `language` for all rows would have \"Filipino\" as their value which makes the `language` column irrelevant for this case. \n",
    "\n",
    "Since we are specifying only Filipino article data, we will use the [`reset_index()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) to update the index of the updated dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "931428fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Jonathon Simmons carried...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – June Mar Fajardo and Sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Nazareth-NU star guard R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – San Miguel waxed hot ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>LeBron James moved closer to Kareem Abdul-Jabb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5598</th>\n",
       "      <td>1</td>\n",
       "      <td>Lambert Strether on 2:00PM Water Cooler 11/4/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5599</th>\n",
       "      <td>1</td>\n",
       "      <td>Open Thread (NOT U.S. Election) 2016-38  News ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5600</th>\n",
       "      <td>1</td>\n",
       "      <td>Black and a member of the 1% elite Page 1 Rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5601</th>\n",
       "      <td>1</td>\n",
       "      <td>MQ-1 Predator unmanned aircraft (Lt Col Leslie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5602</th>\n",
       "      <td>1</td>\n",
       "      <td>Charlie Baker , Massachusetts (2015–present)[3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5603 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            Content\n",
       "0         0  MANILA, Philippines – Jonathon Simmons carried...\n",
       "1         0  MANILA, Philippines – June Mar Fajardo and Sco...\n",
       "2         0  MANILA, Philippines – Nazareth-NU star guard R...\n",
       "3         0  MANILA, Philippines – San Miguel waxed hot ear...\n",
       "4         0  LeBron James moved closer to Kareem Abdul-Jabb...\n",
       "...     ...                                                ...\n",
       "5598      1  Lambert Strether on 2:00PM Water Cooler 11/4/2...\n",
       "5599      1  Open Thread (NOT U.S. Election) 2016-38  News ...\n",
       "5600      1  Black and a member of the 1% elite Page 1 Rela...\n",
       "5601      1  MQ-1 Predator unmanned aircraft (Lt Col Leslie...\n",
       "5602      1  Charlie Baker , Massachusetts (2015–present)[3...\n",
       "\n",
       "[5603 rows x 2 columns]"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filipino_news = df_News[df_News_Language['language'] == 'Filipino'].reset_index(drop=True)\n",
    "df_filipino_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3bfb8-676b-467a-a565-470b558d64a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Separating Real and Fake News Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f3a1d",
   "metadata": {},
   "source": [
    "Of course, the combined news data contains **both real and fake news articles**. \n",
    "\n",
    "With that, we sort these articles into two datasets: (1) `Real news articles` and (2) `Fake news articles`. \n",
    "\n",
    "In separating the combined news data by the article type (`real or new`), we will **rely on the `label` column** of the combined news data as its values indicate if the article is <u>**fake (`label` value: 1)**</u> or <u>**real (`label` value: 0)**</u>. In this case, unlike the separation process of article data by language, we will be <u>using the original copy of the combined news data</u> since the `label` column is already there to indicate which of the articles are fake or real.\n",
    "\n",
    "Before separating the data by article type, let us check the **tally per article type** among the combined news data. To do this, we will use the [`value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "id": "a41dd154-b097-4e94-9356-c4ca6182ab3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18555\n",
       "1     4579\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_News['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d2f00a-2cab-4109-b0a8-bb6c5b273ee9",
   "metadata": {},
   "source": [
    "As seen from the output above, the **`0` label or real news articles has 18,555 rows** while the **`1` label or fake news has 4,579 rows**. Meaning, it is evident that <u>there are a lot more real data collected than the fake news data</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b63658a-7414-4545-9530-e2e143c872fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `Real News` Article Data\n",
    "To do this, a dataframe called `df_real_news` will be created as the container of the real news articles. \n",
    "\n",
    "In this section, we will **collect all the real news articles from the original copy of the combined news data (`df_News`) and put them in the new DataFrame `df_real_news`**. To know which of the rows from the original combined data will be included, we will specify that we will **only retrieve those article data that have `label` value equal to \"0\"**. \n",
    "\n",
    "Since we are specifying only real news article data, we will use the [`reset_index()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) to update the index of the updated dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "id": "40c8dcd5-31eb-4fbe-bc12-097aa1183d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18550</th>\n",
       "      <td>0</td>\n",
       "      <td>Most conservatives who oppose marriage equalit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18551</th>\n",
       "      <td>0</td>\n",
       "      <td>The freshman senator from Georgia quoted scrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18552</th>\n",
       "      <td>0</td>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18553</th>\n",
       "      <td>0</td>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18554</th>\n",
       "      <td>0</td>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18555 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            Content\n",
       "0          0  MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1          0  MANILA, Philippines – The results of the lates...\n",
       "2          0  Tom Brady was the ultimate winner on the field...\n",
       "3          0  It’s one thing to know what makes people happy...\n",
       "4          0  Justin Bieber is the latest artist in a growin...\n",
       "...      ...                                                ...\n",
       "18550      0  Most conservatives who oppose marriage equalit...\n",
       "18551      0  The freshman senator from Georgia quoted scrip...\n",
       "18552      0  The State Department told the Republican Natio...\n",
       "18553      0  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "18554      0  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[18555 rows x 2 columns]"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for real news (where 'label' is 0)\n",
    "df_real_news = df_News[df_News['label'] == 0].copy()\n",
    "df_real_news = df_real_news.reset_index(drop=True)\n",
    "df_real_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b273b-3dd0-4464-9118-09e34dcba890",
   "metadata": {},
   "source": [
    "To add, the `label` for <u>all rows would have \"0\" as their value</u> which will make the `label` column irrelevant for this case. Therefore, we will <u>drop the `label` column</u> in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "8fd17ac5-e5a9-4b33-9877-e054bc410be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MANILA, Philippines – Finally! Best-selling Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MANILA, Philippines – The results of the lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tom Brady was the ultimate winner on the field...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It’s one thing to know what makes people happy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Justin Bieber is the latest artist in a growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18550</th>\n",
       "      <td>Most conservatives who oppose marriage equalit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18551</th>\n",
       "      <td>The freshman senator from Georgia quoted scrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18552</th>\n",
       "      <td>The State Department told the Republican Natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18553</th>\n",
       "      <td>ADDIS ABABA, Ethiopia —President Obama convene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18554</th>\n",
       "      <td>Jeb Bush Is Suddenly Attacking Trump. Here's W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18555 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Content\n",
       "0      MANILA, Philippines – Finally! Best-selling Ja...\n",
       "1      MANILA, Philippines – The results of the lates...\n",
       "2      Tom Brady was the ultimate winner on the field...\n",
       "3      It’s one thing to know what makes people happy...\n",
       "4      Justin Bieber is the latest artist in a growin...\n",
       "...                                                  ...\n",
       "18550  Most conservatives who oppose marriage equalit...\n",
       "18551  The freshman senator from Georgia quoted scrip...\n",
       "18552  The State Department told the Republican Natio...\n",
       "18553  ADDIS ABABA, Ethiopia —President Obama convene...\n",
       "18554  Jeb Bush Is Suddenly Attacking Trump. Here's W...\n",
       "\n",
       "[18555 rows x 1 columns]"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real_news.drop(['label'], axis=1, inplace=True)\n",
    "\n",
    "df_real_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c494e7-6e19-4177-a0b4-18cd53c31e1e",
   "metadata": {},
   "source": [
    "All of this process will also be done in fake news article data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc26978-8454-4c42-a4e6-eccc5b370d74",
   "metadata": {},
   "source": [
    "## `Fake News` Article Data\n",
    "To do this, a dataframe called `df_fake_news` will be created as the container of the fake news articles. \n",
    "\n",
    "In this section, we will **collect all the fake news articles from the original copy of the combined news data (`df_News`) and put them in the new DataFrame `df_fake_news`**. To know which of the rows from the original combined data will be included, we will specify that we will **only retrieve those article data that have `label` value equal to \"1\"**. \n",
    "\n",
    "Since we are specifying only fake news article data, we will use the [`reset_index()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html) to update the index of the updated dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "edcd0e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Isiniwalat ng isang tribal leader ang kabalbal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Kilala ang Univeristy of the Philippines (UP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Ayon kay Tourism Secretary Bernadette Romulo-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Sa opisyal na pagpapakilala ng mga taga-oposis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Hindi pinalampas ni dating Presidential Commun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>1</td>\n",
       "      <td>Written by Peter Van Buren   venerable New Yor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4575</th>\n",
       "      <td>1</td>\n",
       "      <td>DOJ COMPLAINT: Comey Under Fire Over Partisan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>1</td>\n",
       "      <td>Julian Assange has claimed the Hillary Clinton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4577</th>\n",
       "      <td>1</td>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>1</td>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4579 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            Content\n",
       "0         1  Isiniwalat ng isang tribal leader ang kabalbal...\n",
       "1         1  Kilala ang Univeristy of the Philippines (UP) ...\n",
       "2         1  Ayon kay Tourism Secretary Bernadette Romulo-P...\n",
       "3         1  Sa opisyal na pagpapakilala ng mga taga-oposis...\n",
       "4         1  Hindi pinalampas ni dating Presidential Commun...\n",
       "...     ...                                                ...\n",
       "4574      1  Written by Peter Van Buren   venerable New Yor...\n",
       "4575      1  DOJ COMPLAINT: Comey Under Fire Over Partisan ...\n",
       "4576      1  Julian Assange has claimed the Hillary Clinton...\n",
       "4577      1  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "4578      1   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "\n",
       "[4579 rows x 2 columns]"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for fake news (where 'label' is 1)\n",
    "df_fake_news = df_News[df_News['label'] == 1].copy()\n",
    "df_fake_news = df_fake_news.reset_index(drop=True)\n",
    "\n",
    "df_fake_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e50be57-878b-43a6-9a22-3b1615783af4",
   "metadata": {},
   "source": [
    "To add, the `label` for <u>all rows would have \"0\" as their value</u> which will make the `label` column irrelevant for this case. Therefore, we will <u>drop the `label` column</u> in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "00d528c3-3a28-4da5-8cf4-979ee9241f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Isiniwalat ng isang tribal leader ang kabalbal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kilala ang Univeristy of the Philippines (UP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ayon kay Tourism Secretary Bernadette Romulo-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sa opisyal na pagpapakilala ng mga taga-oposis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindi pinalampas ni dating Presidential Commun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4574</th>\n",
       "      <td>Written by Peter Van Buren   venerable New Yor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4575</th>\n",
       "      <td>DOJ COMPLAINT: Comey Under Fire Over Partisan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>Julian Assange has claimed the Hillary Clinton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4577</th>\n",
       "      <td>The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>Anti-Trump Protesters Are Tools of the Oligar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4579 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Content\n",
       "0     Isiniwalat ng isang tribal leader ang kabalbal...\n",
       "1     Kilala ang Univeristy of the Philippines (UP) ...\n",
       "2     Ayon kay Tourism Secretary Bernadette Romulo-P...\n",
       "3     Sa opisyal na pagpapakilala ng mga taga-oposis...\n",
       "4     Hindi pinalampas ni dating Presidential Commun...\n",
       "...                                                 ...\n",
       "4574  Written by Peter Van Buren   venerable New Yor...\n",
       "4575  DOJ COMPLAINT: Comey Under Fire Over Partisan ...\n",
       "4576  Julian Assange has claimed the Hillary Clinton...\n",
       "4577  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...\n",
       "4578   Anti-Trump Protesters Are Tools of the Oligar...\n",
       "\n",
       "[4579 rows x 1 columns]"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake_news.drop(['label'], axis=1, inplace=True)\n",
    "\n",
    "df_fake_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d01ebfc-634e-48d3-9b54-ed46cb6e2cb2",
   "metadata": {},
   "source": [
    "# Final Dataset Description of the Combined News Data\n",
    "\n",
    "By using the [`.info()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.info.html), let us view the final dataset description of the combined news data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "32b40e2d-3543-4dcb-b8e4-9d0562fcff6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23129 entries, 0 to 23128\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    23129 non-null  int64 \n",
      " 1   Content  23129 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 361.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dfNews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66cbe33-7ed8-4968-8cc0-34147f606bda",
   "metadata": {},
   "source": [
    "There are **23,129 rows** for the combined news data after the data preprocessing and data cleaning. To add, both columns have no null values anymore as the information stated that the non-null count for both columns are equal to the total number of rows of the latest combined news data.\n",
    "\n",
    "Since the preprocessing, cleaning, and sorting of data are all done, we will proceed with saving the dataframes and sub-dataframe we have processed and cleaned to `.csv` files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47e4e2",
   "metadata": {},
   "source": [
    "# Saving of Data to CSV files\n",
    "\n",
    "With the help of pandas' [`to_csv()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html), we will be exporting copies of the **several dataframes** and **sub dataframes** as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "d1217737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving of Cleaned Combined News Data to CSV file\n",
    "df_News.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "id": "06ab4c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving of English News to CSV file\n",
    "df_english_news.to_csv('english_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "b324989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving of Filipino News to CSV file\n",
    "df_filipino_news.to_csv('filipino_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "id": "4dc551d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving of Real News to CSV file\n",
    "df_real_news.to_csv('real_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "id": "b8c3fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving of Fake News to CSV file\n",
    "df_fake_news.to_csv('fake_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d96ee8",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ccfaf7",
   "metadata": {},
   "source": [
    "## EDA Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd2c44",
   "metadata": {},
   "source": [
    "The following questions that will be used to explore `df_cleaneddata`, which is the combined dataset:\n",
    "\n",
    "1. Which words occur most frequently in each of the labels?\n",
    "     - Without any exclusion of words\n",
    "     - Excluding Stop Words, Fillers, and Blank Spaces\n",
    "     - Excluding Verbs and Contractions\n",
    "     - WordCloud using TF-IDF\n",
    " \n",
    "2. What is the range of character counts of the news for each of the labels?\n",
    "3. What are the sentiment score of the statements per labels?\n",
    "4. Among the articles written in Filipino and English, which language predominantly contains the most real or fake news labels?\n",
    "\n",
    "To answer these questions, we used numerical summaries. Additionally, we used visualization techiniques in order to present and illustrate possible relationships in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d580fb5d",
   "metadata": {},
   "source": [
    "To start with, we will duplicate the original `df_News` dataframe that holds the merged and cleaned dataset using the [`copy()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.copy.html). This duplicated dataframe will be referred to as \"news\" throughout the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b3e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = df_News[['label', 'Content']].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822b2c52",
   "metadata": {},
   "source": [
    "Afterward, the news dataframe will be split into two separate dataframes based on their respective labels: one for real instances (label = 0), denoted as \"rn,\" and another for fake instances (label = 1), denoted as \"fn.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8fe4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = news[news['label'] == 0] \n",
    "fn = news[news['label'] == 1] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85a762",
   "metadata": {},
   "source": [
    "## 1. Which words occur most frequently in each of the labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38364c27",
   "metadata": {},
   "source": [
    "To find the words that appear most frequently, we will generate separate word clouds for each label. Additionally, we will employ two different methods for creating these word clouds, namely the SpaCy word cloud and a word cloud based on TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a17182",
   "metadata": {},
   "source": [
    "### Word Cloud using SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beecb5e2",
   "metadata": {},
   "source": [
    "**SpaCy** is a freely available Python library that is open-source and widely used for different Natural Language Processing (NLP) tasks such as identifying entities, classifying text, and preparing text for analysis.\n",
    "\n",
    "\n",
    "To begin, we'll merge the Content data within each label by using the [`join()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html?highlight=join#pandas.DataFrame.join) function, combining all the contents belonging to the same label. The use of \" \" as the separator means that the content data within each label will be separated by a whitespace. Additionally, we'll convert all the contents to lowercase using [`lower()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html?highlight=lower#pandas.Series.str.lower) to ensure uniformity in the content's case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d97dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the texts from the Real News and separating it by whitespace\n",
    "text_rn = \" \".join(i for i in rn['Content']).lower()\n",
    "\n",
    "# Combining the texts from the Fake News and separating it by whitespace\n",
    "text_fn = \" \".join(i for i in fn['Content']).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec52c6d5",
   "metadata": {},
   "source": [
    "Afterward, we will create [`WorldClouds()`](https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html) for each label, utilizing the combined text data for each label obtained in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a word cloud for Real News by using the combined text data\n",
    "wordcloud_rn = WordCloud(background_color=\"white\").generate(text_rn)\n",
    "\n",
    "# Generating a word cloud for Fake News by using the combined text data\n",
    "wordcloud_fn = WordCloud(background_color=\"white\").generate(text_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951b251f",
   "metadata": {},
   "source": [
    "The visualization of bot word clouds can now be presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 13))\n",
    "  \n",
    "rows = 1\n",
    "columns = 2\n",
    "  \n",
    "# Plotting the initial word cloud for REAL NEWS\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(wordcloud_rn, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"REAL NEWS\", fontsize=15, weight='bold')\n",
    "\n",
    "# Plotting the initial word cloud for FAKE NEWS\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(wordcloud_fn, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"FAKE NEWS\", fontsize=15, weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1852a",
   "metadata": {},
   "source": [
    "#### Figure 1. Initial Word Cloud for each label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6b4dc",
   "metadata": {},
   "source": [
    "As observed in the word clouds displayed above, they contain numerous extraneous elements like fillers and blank spaces (' '). To enhance data cleanliness, we will eliminate these fillers and blank spaces. Additionally, we will exclude stop words from the data to ensure that only essential and relevant words are shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01906533",
   "metadata": {},
   "source": [
    "### Excluding Stop Words, Fillers, and Blank Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cfac1b",
   "metadata": {},
   "source": [
    "We will first retrieve the stop words from SpaCy and merge them with the fillers and blank spaces identified in the initial word clouds. Subsequently, we will instruct the [`WorldClouds()`](https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html)  to exclude these specific texts and characters when creating new word clouds for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c5703",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Accesing the stopwords package from SpaCy\n",
    "all_stopwords = sp.Defaults.stop_words\n",
    "# List of the fillers and blank space \n",
    "new_stopwords=[\"filler\", \" \", \"S\", \"t\", \"s\", \"u\", \" \"]\n",
    "# Combining the stopwords, fillers, and blank space\n",
    "comb_stopwords=list(new_stopwords)+list(all_stopwords)\n",
    "\n",
    "# Generating the word clouds\n",
    "wordcloud_rn = WordCloud(stopwords=comb_stopwords, background_color=\"white\").generate(text_rn)\n",
    "wordcloud_fn = WordCloud(stopwords=comb_stopwords, background_color=\"white\").generate(text_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea1f2f1",
   "metadata": {},
   "source": [
    "We will now be generating new word clouds that exclude any texts and characters that we removed in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36db575",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 13))\n",
    "  \n",
    "rows = 1\n",
    "columns = 2\n",
    "# Plotting the initial word cloud for Real News\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(wordcloud_rn, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"REAL NEWS\", fontsize=15, weight='bold')\n",
    "\n",
    "# Plotting the initial word cloud for Fake News\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(wordcloud_fn, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"FAKE NEWS\", fontsize=15, weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b49182",
   "metadata": {},
   "source": [
    "#### Figure 2. Updated Word Cloud for each label (Excluded Stopwords, Fillers, and Blank Spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba2c287",
   "metadata": {},
   "source": [
    "In the depicted figure, the wordclouds appear more refined. For the real label, the most prominent words are 'said,' 'year,' 'people,' 'country,' 'added,' and 'time,' indicating their high occurrence in this category. On the other hand, for the fake label, words such as 'trump,' 'clinton,' 'state,' 'said,' and 'people' are found to be the most common occurrences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9667da5f",
   "metadata": {},
   "source": [
    "### Excluding Verbs and Contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae9f52",
   "metadata": {},
   "source": [
    "The next round of word clouds will be created, but this time, we will exclude verbs and contractions from the analysis. To gain more valuable insights from the data, we will treat verbs as stopwords, meaning they will not be included in the word clouds. However, existing libraries do not classify verbs as stopwords by default, so we will manually add them to the current list of stopwords. As a result, the focus will be on nouns, providing a clearer picture for the upcoming word clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcceaf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stopwords = sp.Defaults.stop_words\n",
    "new_stopwords_nv=[\"filler\", \" \", \"S\", \"t\", \"s\", \"u\", \" \", \"added\", \"believe\", \"use\", \"saying\", \"said\", \"tell\", \"help\", \"run\", \"work\", \"says\", \"come\", \"told\", \"like\", \"know\", \"asked\", \"vote\", \"going\", \"make\", \"support\", \"debate\" \"sabi\", \"help\", \"think\", \"provide\", \"▯\"]\n",
    "comb_stopwords=list(new_stopwords_nv)+list(all_stopwords)\n",
    "\n",
    "# Generating the word clouds\n",
    "wordcloud_rn_nv = WordCloud(stopwords=comb_stopwords, background_color=\"white\").generate(text_rn)\n",
    "wordcloud_fn_nv = WordCloud(stopwords=comb_stopwords, background_color=\"white\").generate(text_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee9151",
   "metadata": {},
   "source": [
    "Next, we are going to generate new visualizations using the updated word clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1635ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 13))\n",
    "  \n",
    "rows = 1\n",
    "columns = 2\n",
    "  \n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(wordcloud_rn_nv, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"REAL NEWS (mostly noun)\", fontsize=15, weight='bold')\n",
    "  \n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(wordcloud_fn_nv, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title(\"FAKE NEWS (mostly noun)\", fontsize=15, weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a34aab",
   "metadata": {},
   "source": [
    "#### Figure 3. Latest Word Cloud for each label (Excluded Stopwords, Fillers, Blank Spaces, Verbs, and Contractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a11fb31",
   "metadata": {},
   "source": [
    "From the word clouds shown above, it is evident that the real label prominently displays words like 'people', 'country', 'year', 'time', and 'according' in a visually larger size. Conversely, the fake label exhibits larger words such as 'trump', 'clinton', 'state', 'people', and 'year'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5609286d",
   "metadata": {},
   "source": [
    "### Word Cloud using TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c479555f",
   "metadata": {},
   "source": [
    "To start, we will be making a copy of the Real News data rn and Fake News fn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_tf = rn[['Content']].copy(deep=True)\n",
    "fn_tf = fn[['Content']].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af9a34",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb4eef",
   "metadata": {},
   "source": [
    "We will perform lemmatization using [`WordNetLemmatizer()`](https://www.nltk.org/api/nltk.stem.WordNetLemmatizer.html?highlight=wordnetlemmatizer) first before converting the dataset into TF-IDF vectors o ensure that the words are in their base form and reduced to the most essential form. To achieve this, we have developed the clean_text function, which is responsible for cleaning the text and generating a text free from unnecessary noise and unwanted words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf5124",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "rn_tf[\"text_clean\"] = rn_tf[\"Content\"].apply(lambda s: ' '.join(re.sub(\"[.,!?:;-='...'@#_]\", \" \", s).split()))\n",
    "fn_tf[\"text_clean\"] = fn_tf[\"Content\"].apply(lambda s: ' '.join(re.sub(r'\\d+', '', s).split()))\n",
    "\n",
    "def clean_text(input_txt):\n",
    "    words_rn_tf = input_txt.lower().split()\n",
    "    words_rn_tf = [word for word in words_rn_tf if word not in stop_words and new_stopwords_nv] \n",
    "    words_rn_tf = [lemmatizer.lemmatize(word, pos='v') for word in words_rn_tf]\n",
    "    words_rn_tf = [word for word in words_rn_tf if len(word) > 2]\n",
    "    noise_free_text = \" \".join(words_rn_tf) \n",
    "    return noise_free_text\n",
    "\n",
    "rn_tf[\"text_clean\"] = rn_tf[\"text_clean\"].apply(lambda s: clean_text(s))\n",
    "\n",
    "\n",
    "fn_tf[\"text_clean\"] = fn_tf[\"Content\"].apply(lambda s: ' '.join(re.sub(\"[.,!?:;-='...'@#_]\", \" \", s).split()))\n",
    "fn_tf[\"text_clean\"] = fn_tf[\"Content\"].apply(lambda s: ' '.join(re.sub(r'\\d+', '', s).split()))\n",
    "\n",
    "def clean_text_s(input_txt):\n",
    "    words_fn_tf = input_txt.lower().split()\n",
    "    words_fn_tf = [word for word in words_fn_tf if word not in stop_words and new_stopwords_nv] \n",
    "    words_fn_tf = [lemmatizer.lemmatize(word, pos='v') for word in words_fn_tf]\n",
    "    words_fn_tf = [word for word in words_fn_tf if len(word) > 2]\n",
    "    noise_free_text = \" \".join(words_fn_tf) \n",
    "    return noise_free_text\n",
    "\n",
    "fn_tf[\"text_clean\"] = fn_tf[\"text_clean\"].apply(lambda s: clean_text(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfaa764",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2105d9d",
   "metadata": {},
   "source": [
    "Once the texts have undergone lemmatization, we proceed to apply the TF-IDF vectorizer on both dataframes. To ensure a concise representation, we set the max_features value to 50, which allows us to select only the top 50 words with the highest TF-IDF scores. This approach helps us focus on the most significant words, making the analysis more efficient and meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a419169",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_stop_words = list(text.ENGLISH_STOP_WORDS.union([\"ll\", \"gt\", \"lt\", \"filler\", \"don\", \"ve\"]))\n",
    "\n",
    "# Initialization of TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1), stop_words=tfidf_stop_words, max_features=50)\n",
    "\n",
    "# Implementing vectorization per label lemmatized data\n",
    "df_vec_rn = tfidf_vectorizer.fit_transform(rn_tf[\"text_clean\"])\n",
    "df_vec_fn = tfidf_vectorizer.fit_transform(fn_tf[\"text_clean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e701ee03",
   "metadata": {},
   "source": [
    "After this step, the resulting matrix will be transformed into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704386ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rn_tf = pd.DataFrame(df_vec_rn.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "df_fn_tf = pd.DataFrame(df_vec_fn.toarray(), columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45807cc0",
   "metadata": {},
   "source": [
    "#### Result data for Real  News label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63586e8",
   "metadata": {},
   "source": [
    "We can observe the frequency score of each word (from the top 50 words) for every data entry in the real news label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce4787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_rn_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ca99f4",
   "metadata": {},
   "source": [
    "#### Result data for Fake News label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1461f29",
   "metadata": {},
   "source": [
    "The same can be observed in the fake news label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9440c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fn_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4954a",
   "metadata": {},
   "source": [
    "Next, we will examine the top 50 words that have been chosen and arrange them based on the overall frequency scores in each data point for each category. We will employ the [`sum()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html?highlight=sum#pandas.DataFrame.sum) function to calculate the total occurrence count of each word across all data points within a specific label. Once this is done, we will use the [`sort_values()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html?highlight=sort_values#pandas.DataFrame.sort_values) method to arrange the words in ascending order, based on their total occurrence values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3663f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_counter_rn = df_rn_tf.T.sum(axis=1).sort_values(ascending=False)\n",
    "tf_idf_counter_fn = df_fn_tf.T.sum(axis=1).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a83005",
   "metadata": {},
   "source": [
    "#### Ranking words for the real news label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0721906",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf_idf_counter_rn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee8205d",
   "metadata": {},
   "source": [
    "Here, the top 5 most frequent words in the real label are as follows:\n",
    "\n",
    "- \"tell\" with a frequency of 4378.469819\n",
    "- \"campaign\" with a frequency of 3806.423478\n",
    "- \"percent\" with a frequency of 1723.544565\n",
    "- \"republican\" with a frequency of 1202.855044\n",
    "- \"republicans\" with a frequency of 1190.927968"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9f17b",
   "metadata": {},
   "source": [
    "#### Ranking words for the fake news label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f613319",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_counter_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1bd70",
   "metadata": {},
   "source": [
    "On the other hand, the most common words in the fake label are:\n",
    "\n",
    "- \"ang\" with a frequency of 1263.425062\n",
    "- \"say\" with a frequency of 636.665587\n",
    "- \"mga\" with a frequency of 624.349292\n",
    "- \"trump\" with a frequency of 573.280842\n",
    "- \"clinton\" with a frequency of 388.996185"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b761187",
   "metadata": {},
   "source": [
    "To create the word cloud using TF-IDF, the [`generate_from_frequencies()`](https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html) function is utilized instead of the [`generate()`](https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28954f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_tf_rn = WordCloud(width = 3000, height = 2000, random_state=1,background_color='white', colormap='Set2', collocations=False).generate_from_frequencies(tf_idf_counter_rn)\n",
    "\n",
    "wordcloud_tf_fn = WordCloud(width = 3000, height = 2000, random_state=1,background_color='white', colormap='Set2', collocations=False).generate_from_frequencies(tf_idf_counter_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f97eab",
   "metadata": {},
   "source": [
    "Having created a word cloud for each label, we can now visualize and compare the differences in word frequency scores between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ed187",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 13))\n",
    "rows = 1\n",
    "columns = 2\n",
    "\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "plt.imshow(wordcloud_tf_rn, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"REAL NEWS\", fontsize=15, weight='bold')\n",
    "\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(wordcloud_tf_fn, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"FAKE NEWS\", fontsize=15, weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ba1aa",
   "metadata": {},
   "source": [
    "### Figure 4. Word Cloud after TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2025263f",
   "metadata": {},
   "source": [
    "As shown in figure above, it is clear that the top 5 words for the real label are \"tell,\" \"campaign,\" \"percent,\" \"republican,\" and \"republicans.\" Conversely, the top 5 words for the fake label are \"ang,\" \"say,\" \"mga,\" \"trump,\" and \"said.\" \n",
    "\n",
    "Nevertheless, relying solely on the word cloud might be misleading as some words appear almost as large as the actual top 5 words in each label. To get a more accurate understanding of the top words in each label, it is advisable to examine the ranking of words based on their frequency scores. This way, we can identify the most significant words in each class more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba5fe3",
   "metadata": {},
   "source": [
    "## 2. What is the range of character counts of the news for each of the labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca8c4f",
   "metadata": {},
   "source": [
    "### REAL NEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897b2901",
   "metadata": {},
   "source": [
    "Firstly, we'll create a duplicate of the dataframe that exclusively includes data from the real label. This duplicate will be referred to as \"rn_2.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ecdf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_2 = rn[['Content']].copy(deep=True)\n",
    "rn_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b79b1c",
   "metadata": {},
   "source": [
    "In the real label, the length of each statement is determined by counting the number of words using the [`count()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.count.html?highlight=count#pandas.Series.str.count) function, and then adding 1 to account for the offset, which gives us the \"length\" variable. Additionally, the length of each statement is measured by the number of characters using the [`len()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.len.html?highlight=len#pandas.Series.str.len) function to count the characters in each text data, resulting in the \"LoR\" variable.\n",
    "\n",
    "Next, the \"length\" and \"LoR\" values are placed in separate columns within the rn_2 dataframe for further analysis and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8de800",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_2['length'] = rn_2['Content'].str.count(' ') + 1\n",
    "rn_2['LoR'] = rn_2['Content'].str.len()\n",
    "rn_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f47220",
   "metadata": {},
   "source": [
    "Afterward, the average length (number of words in a text data) and the average LoR (number of characters in a text data) are computed by using the [`mean()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html?highlight=mean#pandas.DataFrame.mean) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074c3489",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_2[\"length\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_2[\"LoR\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b6ba70",
   "metadata": {},
   "source": [
    "According to the findings above, the average statement length in the real label is approximately 400 words. Additionally, the average number of characters is approximately 2444 characters per statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b716b",
   "metadata": {},
   "source": [
    "### FAKE NEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035166cf",
   "metadata": {},
   "source": [
    "Now, we will be doing the same process as what we did in the real label with fake label. The only difference is that we will be making a copy of the dataframe which only contain data under the fake label and will be renamed as fn_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb30d342",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fn_2 = fn[['Content']].copy(deep=True)\n",
    "fn_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c5946",
   "metadata": {},
   "source": [
    "Similar to what we did in the rn_2 dataframe, the \"length\" and \"LoR\" values are placed in separate columns within the fn_2 dataframe for further analysis and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f52bd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fn_2['length'] = fn_2['Content'].str.count(' ') + 1\n",
    "fn_2['LoR'] = fn_2['Content'].str.len()\n",
    "fn_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ee60d",
   "metadata": {},
   "source": [
    "The average length (number of words in a text data) and the average LoR (number of characters in a text data) are also computed by using the [`mean()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html?highlight=mean#pandas.DataFrame.mean) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_2[\"length\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d12174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_2[\"LoR\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdff343",
   "metadata": {},
   "source": [
    "From the data shown above, we observe that the average length of statements in the fake label is approximately 703 words. Additionally, the average length number of characters is found to be around 4199 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe161447",
   "metadata": {},
   "source": [
    "Comparing the results of the two label, it is evident that the fake label has a greater average length of statements as compared to real label. The same can be said when it comes to the number of characters of each label. This difference suggests that fake news content may involve more elaborate narratives, potentially using sensationalized language to capture attention and present a sense of credibility. Longer statements could also aim to overwhelm readers with excessive information, making fact-checking more challenging. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840f4c26",
   "metadata": {},
   "source": [
    "## 3. What are the sentiment score of the statements per labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce9605",
   "metadata": {},
   "source": [
    "Again, like how it was done before in the two previous question, we will be creating a copy of the real news and fake news label dataframes for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf727de",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn_SA = rn.copy(deep=True)\n",
    "fn_SA = fn.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e8d5a7",
   "metadata": {},
   "source": [
    "## Real News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060548f8",
   "metadata": {},
   "source": [
    "Firstly, the text column in the dataframes will be converted to lowercase using the [`lower()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.lower.html?highlight=lower#pandas.Series.str.lower) function. Afterward, tokenization will be applied using the [`RegexpTokenizer`](https://www.nltk.org/api/nltk.tokenize.regexp.html) to facilitate sentiment analysis at a token level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d350eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase the texts\n",
    "rn_SA['Content'] = rn_SA['Content'].astype(str).str.lower() #real news\n",
    "fn_SA['Content'] = fn_SA['Content'].astype(str).str.lower() #fake news\n",
    "\n",
    "# Initialize tokenizer\n",
    "regexp = RegexpTokenizer('\\w+')\n",
    "\n",
    "# Apply tokenizer\n",
    "rn_SA['text_token']= rn_SA['Content'].apply(regexp.tokenize) #real news\n",
    "fn_SA['text_token']= fn_SA['Content'].apply(regexp.tokenize) #fake news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3210696",
   "metadata": {},
   "source": [
    "Following the tokenization process, a new column will be appended to the dataframes, containing the tokenized statements combined into a single text string. Before tokenization, the [`stopwords`](https://www.nltk.org/howto/corpus.html?highlight=stopwords) package was employed to identify and remove stopwords and other irrelevant words, thereby enhancing processing efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3656120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stopwords\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "my_stopwords = ['https']\n",
    "stopwords.extend(my_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51f6328",
   "metadata": {},
   "source": [
    "stopwords is then removed from the tokenized text data and converts the processed tokens back into strings for real news dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e5a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Real News\n",
    "rn_SA['text_token'] = rn_SA['text_token'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "rn_SA['text_string'] = rn_SA['text_token'].apply(lambda x: ' '.join([item for item in x if len(item)>2]))\n",
    "rn_SA[['Content', 'text_token', 'text_string']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc6aa49",
   "metadata": {},
   "source": [
    "The same process is applied to the DataFrame fn_SA to process the text data for fake news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c93b53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fake News\n",
    "fn_SA['text_token'] = fn_SA['text_token'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "fn_SA['text_string'] = fn_SA['text_token'].apply(lambda x: ' '.join([item for item in x if len(item)>2]))\n",
    "fn_SA[['Content', 'text_token', 'text_string']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914cbf40",
   "metadata": {},
   "source": [
    "The text, which has already been tokenized, will now undergo re-tokenization using the nltk tokenize package, this time based on space and punctuation. Then, [`FreqDist`](https://www.nltk.org/api/nltk.probability.FreqDist.html?highlight=freqdist) is utilized to calculate the frequency of each word in a statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef653b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Real News\n",
    "all_words = ' '.join([word for word in rn_SA['text_string']])\n",
    "tokenized_words = nltk.tokenize.word_tokenize(all_words)\n",
    "\n",
    "fdist = FreqDist(tokenized_words)\n",
    "\n",
    "rn_SA['text_string_fdist'] = rn_SA['text_token'].apply(lambda x: ' '.join([item for item in x if fdist[item] >= 1 ]))\n",
    "rn_SA[['Content', 'text_token', 'text_string', 'text_string_fdist']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d178a67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fake News\n",
    "all_words = ' '.join([word for word in fn_SA['text_string']])\n",
    "\n",
    "fn_SA['text_string_fdist'] = fn_SA['text_token'].apply(lambda x: ' '.join([item for item in x if fdist[item] >= 1 ]))\n",
    "fn_SA[['Content', 'text_token', 'text_string', 'text_string_fdist']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5afa76",
   "metadata": {},
   "source": [
    "Following that, lemmatization is implemented using [`WordNetLemmatizer()`](https://www.nltk.org/api/nltk.stem.WordNetLemmatizer.html?highlight=wordnetlemmatizer) to group words with the same base form together, treating them as one for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Real News\n",
    "wordnet_lem = WordNetLemmatizer()\n",
    "\n",
    "rn_SA['text_string_lem'] = rn_SA['text_string_fdist'].apply(wordnet_lem.lemmatize)\n",
    "\n",
    "# check if the columns are equal\n",
    "rn_SA['is_equal']= (rn_SA['text_string_fdist']== rn_SA['text_string_lem'])\n",
    "# show level count\n",
    "rn_SA.is_equal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6346b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fake News\n",
    "\n",
    "fn_SA['text_string_lem'] = fn_SA['text_string_fdist'].apply(wordnet_lem.lemmatize)\n",
    "\n",
    "# check if the columns are equal\n",
    "fn_SA['is_equal']= (fn_SA['text_string_fdist'] == fn_SA['text_string_lem'])\n",
    "# show level count\n",
    "fn_SA.is_equal.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbcd96c",
   "metadata": {},
   "source": [
    "In this analysis, the lemmatized text string undergoes sentiment analysis, which involves generating negative, neutral, positive, and compound scores for each statement. The compound score represents the overall sentiment of the statement. [`NLTK Sentiment Analysis`](https://www.nltk.org/api/nltk.sentiment.html?highlight=nltk+sentiment+analysis) will be employed to perform sentiment analysis in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c564beb",
   "metadata": {},
   "source": [
    "### NLTK Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937305df",
   "metadata": {},
   "source": [
    "### Real News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058577d5",
   "metadata": {},
   "source": [
    "To perform sentiment analysis on the lemmatized text in the dataframe, the [`SentimentIntensityAnalyzer`](https://www.nltk.org/api/nltk.sentiment.SentimentIntensityAnalyzer.html?highlight=sentimentintensityanalyzer#nltk.sentiment.SentimentIntensityAnalyzer) from the NLTK library will be used wherein it would calculate the polarity scores for each statement and assigns them to a new column called \"polarity\" in the same dataframe. After that, the data structure will be modified by dropping the original \"polarity\" column and concatenating the scores from the \"polarity\" column into separate columns: \"negative,\" \"neutral,\" \"positive,\" and \"compound.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16e1785",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "rn_SA['polarity'] = rn_SA['text_string_lem'].apply(lambda x: analyzer.polarity_scores(x))\n",
    "\n",
    "# Change data structure\n",
    "rn_SA = pd.concat(\n",
    "     [rn_SA.drop(['polarity'], axis=1), \n",
    "     rn_SA['polarity'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1602291b",
   "metadata": {},
   "source": [
    "Each statement's sentiment is categorized based on its compound score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9745a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition(x):\n",
    "    if x>0:\n",
    "        return \"positive\"\n",
    "    elif x==0:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "rn_SA['sentiment'] = rn_SA['compound'].apply(condition)\n",
    "\n",
    "rn_SA.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62770c3",
   "metadata": {},
   "source": [
    "We will be utilizing the [`value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html?highlight=value_counts#pandas.DataFrame.value_counts) function to examine the total number of positive, negative, and neutral statements in the real news label. The results indicate that a majority of the statements in this label are categorized as having a positive sentiment, however, there is still a significant number of statements with negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c61f0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rn_SA['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da16d0b2",
   "metadata": {},
   "source": [
    "To visualize this distribution, a [`bar plot`](https://seaborn.pydata.org/generated/seaborn.barplot.html?highlight=vertical+bar+plots) is generated to represent the count of each sentiment category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920db293",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('muted')\n",
    "ax = sns.barplot(x=rn_SA['sentiment'].value_counts().index, y=rn_SA['sentiment'].value_counts())\n",
    "ax.set_title('Real News label Sentiment Text Values by Counts', fontsize=18, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797be47",
   "metadata": {},
   "source": [
    "#### Figure 5. Real News label Sentiment Text Values by Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a81029b",
   "metadata": {},
   "source": [
    "From this figure, positive texts (8920) has the highest quantity for the real news label. Another finding from this figure is that there are more negative texts (8540) than neutral texts (1176) in this label. This suggests that the content in the real news dataset tends to convey positive or favorable information. On the other hand, the presence of a significant number of negative texts indicates that there are also instances of negative or unfavorable information being reported in the real news dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c223cc3e",
   "metadata": {},
   "source": [
    "## Fake News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be84a57e",
   "metadata": {},
   "source": [
    "The same process as the rn_SA dataframe will be applied to the fn_SA dataframe to perform sentiment analysis on the lemmatized text in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6615a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_SA['polarity'] = fn_SA['text_string_lem'].apply(lambda x: analyzer.polarity_scores(x))\n",
    "\n",
    "# Change data structure\n",
    "fn_SA = pd.concat(\n",
    "     [fn_SA.drop(['polarity'], axis=1), \n",
    "     fn_SA['polarity'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb931e7",
   "metadata": {},
   "source": [
    "Each statement's sentiment is categorized based on its compound score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ab014",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_SA['sentiment'] = fn_SA['compound'].apply(condition)\n",
    "\n",
    "fn_SA.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5850840b",
   "metadata": {},
   "source": [
    "For the Fake News, it shows that the majority of the statements are categorized as also having positive sentiment, and also with negative sentiments being the second highest and neutral sentiment being the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db91e315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fn_SA['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ba5601",
   "metadata": {},
   "source": [
    "To visualize the distribution for the Fake News label, a [`bar plot`](https://seaborn.pydata.org/generated/seaborn.barplot.html?highlight=vertical+bar+plots) is generated as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4834a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('muted')\n",
    "ax = sns.barplot(x= fn_SA['sentiment'].value_counts().index, y=fn_SA['sentiment'].value_counts())\n",
    "ax.set_title('Fake News label Sentiment Text Values by Counts', fontsize=18, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579968e3",
   "metadata": {},
   "source": [
    "#### Figure 6. Real News label Sentiment Text Values by Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60efeff2",
   "metadata": {},
   "source": [
    "The figure illustrates the distribution of sentiments within the fake news label. It indicates that the majority of statements in the fake news dataset are classified as positive, with a count of 2587 statements. The second-highest sentiment category is negative, with 1734 statements. The smallest category is neutral, comprising only 177 statements. This distribution provides valuable insights into the overall sentiment patterns within the fake news dataset, highlighting the prevalence of positive sentiments and the relatively lower occurrence of neutral sentiments.\n",
    "\n",
    "The sentiment distribution within the fake news dataset reveals three key implications:\n",
    "   - a higher count of positive statements suggests that a significant portion of the fake news articles convey a positive or favorable tone, possibly aiming to promote specific narratives and influence readers' perceptions. \n",
    "   \n",
    "   - the considerable number of negative statements indicates that fake news articles also employ negative language to invoke emotional responses and create a sense of urgency. This polarization in sentiment can contribute to the spread of misinformation, as emotionally charged content tends to attract more attention and engagement.\n",
    "   \n",
    "  - the relatively lower number of neutral statements further reinforces the notion that fake news often employs polarizing and emotive language to create impact and engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e6851",
   "metadata": {},
   "source": [
    "## 4. Among the articles written in Filipino and English, which language predominantly contains the most real or fake news labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa08e2ff",
   "metadata": {},
   "source": [
    "To answer this question, we would be needing to load the csv files, using [`read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html?highlight=read_csv#pandas.read_csv) for English news and Filipino news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb61264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english_news = pd.read_csv('english_news.csv')\n",
    "df_english_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf9e1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filipino_news = pd.read_csv('filipino_news.csv')\n",
    "df_filipino_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105aec4b",
   "metadata": {},
   "source": [
    "To count the number of real and fake news labels, we filter the dataframes based on the 'label' column. We then calculate the counts of real and fake news labels using the shape attribute of the filtered dataframes. The shape attribute returns a tuple (rows, columns), so shape[0] gives us the number of rows or the count of real/fake news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f0394d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "english_real_count = df_english_news[df_english_news['label'] == 0].shape[0]\n",
    "english_fake_count = df_english_news[df_english_news['label'] == 1].shape[0]\n",
    "\n",
    "filipino_real_count = df_filipino_news[df_filipino_news['label'] == 0].shape[0]\n",
    "filipino_fake_count = df_filipino_news[df_filipino_news['label'] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4483fae4",
   "metadata": {},
   "source": [
    "We then compare the counts for English and Filipino news to determine which language has the most real and fake news labels. We use if-else statements to assign the most frequent language to variables most_real_language and most_fake_language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5aa3a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare the counts to determine which language has the most real and fake news labels\n",
    "if english_real_count > filipino_real_count:\n",
    "    most_real_language = 'English'\n",
    "    most_real_count = english_real_count\n",
    "else:\n",
    "    most_real_language = 'Filipino'\n",
    "    most_real_count = filipino_real_count\n",
    "\n",
    "if english_fake_count > filipino_fake_count:\n",
    "    most_fake_language = 'English'\n",
    "    most_fake_count = english_fake_count\n",
    "else:\n",
    "    most_fake_language = 'Filipino'\n",
    "    most_fake_count = filipino_fake_count\n",
    "\n",
    "# Display the results\n",
    "print(f\"Language with the most Real News: {most_real_language}, Count: {most_real_count}\")\n",
    "print(f\"Language with the most Fake News: {most_fake_language}, Count: {most_fake_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dfa33e",
   "metadata": {},
   "source": [
    "We also create a [`bar plot`](https://seaborn.pydata.org/generated/seaborn.objects.Stack.html?highlight=bar+stack+plot) to visualize this result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot to visualize the counts\n",
    "languages = ['English', 'Filipino']\n",
    "real_counts = [english_real_count, filipino_real_count]\n",
    "fake_counts = [english_fake_count, filipino_fake_count]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(languages, real_counts, color='green', label='Real News')\n",
    "plt.bar(languages, fake_counts, bottom=real_counts, color='red', label='Fake News')\n",
    "plt.xlabel('Language')\n",
    "plt.ylabel('Number of News')\n",
    "plt.title('Number of Real and Fake News by Language')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a580b05",
   "metadata": {},
   "source": [
    "#### Figure 7. Number of Real and Fake News by Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b7a7c",
   "metadata": {},
   "source": [
    "Based on the provided counts, English has the highest number of both real and fake news labels. There are 14,419 real news articles and 3,107 fake news articles written in English. However, it's important to note that we have more English articles in the dataset compared to Filipino articles, which may skew the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028fab13",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "After examining the data for Fake and Real news, the initial analysis suggests that we need more data for both categories (Real and Fake). This is evident upon comparing the most common words result from using the TF-IDF method (refer to `Figure 4`) and the most common words result from manually removing unnecessary words and characters from the data such as stopwords, fillers, blank spaces, verbs, and contractions (refer to `Figure 3`). \n",
    "\n",
    "The result from the manual exclusion of the unnecessary words and characters on both data per label had listed the most common words under the real label which are: 'people', 'country', 'year', 'time', and 'according'. Meanwhile, the most common words under the fake label are 'trump', 'clinton', 'state', 'people', and 'year'. On the other hand, using the TF-IDF method to identify common words, the top 5 words for the Real label are \"tell,\" \"campaign,\" \"percent,\" \"republican,\" and \"republicans.\" For the Fake label, the top 5 words are \"ang,\" \"say,\" \"mga,\" \"trump,\" and \"said.\" Upon comparing the outcomes of both methods (see `Figure 3` and `Figure 4`), we **no shared frequent words** were found in the <u>Real label from both results</u>. However, for the <u>fake label</u>, only the word **'trump' appeared in both sets of results**. Additionally, as observed in the TF-IDF results, a **mixture of Filipino and English words** were included among the most common words in the Fake label.\n",
    "\n",
    "Continuing further, when investigating the languages represented within the gathered data, it becomes apparent that we require additional Filipino news articles to establish a meaningful comparison with the English articles. This will enable us to determine which of the two languages is more susceptible to containing fake news data.\n",
    "\n",
    "As depicted in `Figure 7`, the results indicate that <u>fake news data is more prevalent within the English articles</u>. However, upon closer examination of the collected data from Filipino and English articles, it becomes evident that the **number of English articles is more than three times that of the Filipino articles**. This <u>big difference in numbers means that the comparison not reliable</u>.\n",
    "\n",
    "\n",
    "# Recommendation\n",
    "To enhance the accuracy and depth of our analysis regarding the prevalence of fake news in both English and Filipino news articles, we suggest the following:\n",
    "\n",
    "### 1. Separate Analysis for Different Languages\n",
    "Conduct separate analysis for news articles written in English and those in Filipino. This will allow us to gain a comprehensive understanding of the distinct patterns and characteristics of fake news propagation in each language.\n",
    "\n",
    "### 2. Expand Data Collection Efforts:\n",
    "Increase the volume of collected data, particularly for Filipino news articles and Fake news articles, to ensure a balanced representation for both languages and for both article types. A larger dataset will contribute to more reliable and insightful conclusions. \n",
    "#### a. Collect More Filipino Article Data from Filipino News Sites\n",
    "Collect or specifically web scrape data from news sites that has Filipino news articles or known for releasing news articles written in Filipino.\n",
    "#### b. Collect from News Sites or Sources known for spreading Fake News\n",
    "Web scrape news sites such as [`Ako'y Pilipino`](http://akoy-pilipino.blogspot.com/), [`Maharlika News`](https://www.maharlikanews.com/) and more sites known for fake news. Also, try cllecting from social media sources that are also known for posting fake news data. This is to gain different forms of fake news data.\n",
    "\n",
    "### 3. More In-Depth Analysis on the Article Data:\n",
    "Undertake a more comprehensive and in-depth analysis by considering the following article information:\n",
    "#### a. Article Titles and Previews Analysis:\n",
    "Collect article titles and previews and examine if there are specific patterns that are prevalent in both real and fake news articles. This could involve comparing wording styles or linguistic cues in both real and fake news titles and previews.\n",
    "#### b. Temporal Analysis:\n",
    "Collect article dates and investigate when the dissemination of fake news data reached its peak. This analysis may also be correlated with significant events or occurrences during those periods across the globe. Identifying any correlation between fake news spikes and major events can provide valuable insights into the motivations and contexts driving the spread of misinformation.\n",
    "\n",
    "These recommendations were formulated while aiming to improve the accuracy and depth of our analysis on fake news prevalence in this project. Implementing these recommendation in future projects may contribute to a deeper understanding of how fake news is distributed, along with its potential impacts across different languages and on a national or global scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b57fa",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ed77e0",
   "metadata": {},
   "source": [
    "- Casayuran, M. (2023, May 3). *Robin: PH press freedom remains under threat due to disinformation, fake news*. Manila Bulletin. https://mb.com.ph/2023/5/2/robin-ph-press-freedom-remains-under-threat-due-to-disinformation-fake-news\n",
    "- Gregorio,  Xave . (2022, October 11). *For Filipinos, fake news is a problem they blame on social media influencers*. Philstar. https://www.philstar.com/headlines/2022/10/11/2215867/filipinos-fake-news-problem-they-blame-social-media-influencers/amp/\n",
    "- Lalu, G. P. (2022, October 11). *‘Fake news’ a problem in PH? 9 in 10 Filipinos agree, says Pulse Asia*. INQUIRER.Net. https://newsinfo.inquirer.net/1678248/fake-news-a-problem-in-ph-9-in-10-filipinos-agree-says-pulse-asia/amp\n",
    "- Sharanya. (2021). *Fake news detection*. Kaggle. https://www.kaggle.com/code/sharanya02/fake-news-detection\n",
    "- Siar, S. (2021, August). *Fake news, its dangers, and how we can fight it*. https://;https://pidswebs.pids.gov.ph/CDN/PUBLICATIONS/pidspn2106.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
